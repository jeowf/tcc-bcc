{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import transformers\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import math\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import SpatialDropout1D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypath = 'E:/Code/prf-recursos-multas/outputs'\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "\n",
    "outfile = 'E:/Code/prf-recursos-multas/dataset/multas.csv'\n",
    "\n",
    "sepc = '`'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(outfile, 'a', encoding='utf-8') as file:\n",
    "    file.write('arquivo' + sepc + 'parecer' + sepc + 'cod_multa' + sepc + 'texto\\n')\n",
    "    file.close()\n",
    "\n",
    "for f in onlyfiles:\n",
    "    fpath = mypath + '/' + f\n",
    "    #print(fpath)\n",
    "    line = ''\n",
    "    \n",
    "    x = f.split('+')\n",
    "    if (len(x) != 3):\n",
    "        continue\n",
    "    for e in x:\n",
    "        line += e + sepc\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    with open(fpath, 'r', encoding='utf-8') as file:\n",
    "        fstr = file.read().replace('\\n', '%EOL%').replace(sepc, '')\n",
    "        line += fstr + \"\\n\"\n",
    "        file.close()\n",
    "\n",
    "    #print(file)    \n",
    "        \n",
    "    with open(outfile, 'a', encoding='utf-8') as file:\n",
    "        file.write(line)\n",
    "        file.close()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepc = '`'\n",
    "\n",
    "df_path_1 = 'E:/Code/prf-recursos-multas/datasets/multas.csv'\n",
    "df_path_2 = 'E:/Code/prf-recursos-multas/datasets/multas_v2.csv'\n",
    "\n",
    "df1 = pd.read_csv(df_path_1, sep=sepc, encoding='utf-8')\n",
    "df2 = pd.read_csv(df_path_2, sep=sepc, encoding='utf-8')\n",
    "\n",
    "def remove_txt(row):  \n",
    "    return row['cod_multa'].replace('.txt','')\n",
    "df1['cod_multa'] = df1.apply(remove_txt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arquivo</th>\n",
       "      <th>parecer</th>\n",
       "      <th>cod_multa</th>\n",
       "      <th>texto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>processo-08664010983201828_text</td>\n",
       "      <td>I</td>\n",
       "      <td>50610</td>\n",
       "      <td>Eu, acima identificado venho por meio deste fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>processo-08664011015201839_text</td>\n",
       "      <td>I</td>\n",
       "      <td>59670</td>\n",
       "      <td>ILMO SENHOR SUPERINTENDENTE DA POLICIA RODOVIA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>processo-08664011027201863_text</td>\n",
       "      <td>I</td>\n",
       "      <td>54282</td>\n",
       "      <td>ILUSTRISSIMO SENHOR, PRESIDENTE DA JARI, DO De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>processo-08664011030201887_text</td>\n",
       "      <td>I</td>\n",
       "      <td>54521</td>\n",
       "      <td>JOZIVAN HELIO DE ARAUJO vem tempestivamente e ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>processo-08664011031201821_text</td>\n",
       "      <td>I</td>\n",
       "      <td>54521</td>\n",
       "      <td>JOZIVAN HELIO DE ARAUJO vem tempestivamente e ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>SEI_08664.012658_2020_14</td>\n",
       "      <td>I</td>\n",
       "      <td>58194</td>\n",
       "      <td>%EOL%%EOL%MINISTERIO DA JUSTICA%EOL%DEPARTAME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>SEI_08664.012690_2020_08</td>\n",
       "      <td>I</td>\n",
       "      <td>59670</td>\n",
       "      <td>%EOL%%EOL%ILUSTRISSIMO SENHOR SUPERINTENDENTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>SEI_08664.012699_2020_19</td>\n",
       "      <td>I</td>\n",
       "      <td>50100</td>\n",
       "      <td>%EOL%%EOL% %EOL%%EOL% %EOL%%EOL%EXCELENTISSIM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>SEI_08664.012707_2020_19</td>\n",
       "      <td>I</td>\n",
       "      <td>51691</td>\n",
       "      <td>%EOL%%EOL%.  REQUERIMENTO DE DEFESA PREVIA%EO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>SEI_08667.024579_2020_26</td>\n",
       "      <td>I</td>\n",
       "      <td>69630</td>\n",
       "      <td>%EOL%%EOL%TOMAZ%EOL%ie PA | EMALANQUNI%EOL%ou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1148 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             arquivo parecer cod_multa  \\\n",
       "0    processo-08664010983201828_text       I     50610   \n",
       "1    processo-08664011015201839_text       I     59670   \n",
       "2    processo-08664011027201863_text       I     54282   \n",
       "3    processo-08664011030201887_text       I     54521   \n",
       "4    processo-08664011031201821_text       I     54521   \n",
       "..                               ...     ...       ...   \n",
       "151         SEI_08664.012658_2020_14       I     58194   \n",
       "152         SEI_08664.012690_2020_08       I     59670   \n",
       "153         SEI_08664.012699_2020_19       I     50100   \n",
       "154         SEI_08664.012707_2020_19       I     51691   \n",
       "155         SEI_08667.024579_2020_26       I     69630   \n",
       "\n",
       "                                                 texto  \n",
       "0    Eu, acima identificado venho por meio deste fo...  \n",
       "1    ILMO SENHOR SUPERINTENDENTE DA POLICIA RODOVIA...  \n",
       "2    ILUSTRISSIMO SENHOR, PRESIDENTE DA JARI, DO De...  \n",
       "3    JOZIVAN HELIO DE ARAUJO vem tempestivamente e ...  \n",
       "4    JOZIVAN HELIO DE ARAUJO vem tempestivamente e ...  \n",
       "..                                                 ...  \n",
       "151   %EOL%%EOL%MINISTERIO DA JUSTICA%EOL%DEPARTAME...  \n",
       "152   %EOL%%EOL%ILUSTRISSIMO SENHOR SUPERINTENDENTE...  \n",
       "153   %EOL%%EOL% %EOL%%EOL% %EOL%%EOL%EXCELENTISSIM...  \n",
       "154   %EOL%%EOL%.  REQUERIMENTO DE DEFESA PREVIA%EO...  \n",
       "155   %EOL%%EOL%TOMAZ%EOL%ie PA | EMALANQUNI%EOL%ou...  \n",
       "\n",
       "[1148 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262152"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set([])\n",
    "\n",
    "for x in df[\"texto\"]:\n",
    "    for y in x.split(\" \"):\n",
    "        if (len(y) > 0 and y[0] != '%'):\n",
    "            vocab.add(y)\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PrÃ©-processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.texto = df.texto.str.replace('%EOL%','\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.texto = df.texto.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RemoÃ§Ã£o de caracteres invÃ¡lidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = \"abcdefghijklmnopqrstuvxzywÃ§\" + \"Ã Ã¡Ã¢Ã£Ã©ÃªÃ­Ã³ÃµÃ´Ãº\"\n",
    "other = \"\\n\" + \" \" + \"\\t\" + \".,?!:;\"\n",
    "\n",
    "valid_characters = list(alphabet + other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_characters(row):\n",
    "    txt = ''\n",
    "    \n",
    "    al = list(alphabet)\n",
    "    ot = list(other)\n",
    "    \n",
    "    for c in row.texto:\n",
    "        if (str(c) in ot):\n",
    "            txt += ' '\n",
    "        elif (str(c) in al):\n",
    "            txt += c\n",
    "    \n",
    "    row.text = txt\n",
    "    return txt\n",
    "df[\"texto2\"] = df.apply(clean_text_characters, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RemoÃ§Ã£o das stopwords\n",
    "\n",
    "Link Ãºtil: http://www.nltk.org/howto/portuguese_en.html\n",
    "\n",
    "Caso necessÃ¡iro, mais stopwords: https://gist.github.com/alopes/5358189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['de', 'a', 'o', 'que', 'e', 'Ã©', 'do', 'da', 'em', 'um']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "stopwords[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords += \".,?!:;\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(row):\n",
    "    txt = []\n",
    "    #print(type(row.texto2))\n",
    "    tokens = nltk.word_tokenize(row.texto2)\n",
    "    for t in tokens:\n",
    "        if (not t in stopwords):\n",
    "            txt.append(t)\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"texto3\"] = df.apply(remove_stop_words, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "def stemming(row):\n",
    "    txt = []\n",
    "    #print(type(row.texto2))\n",
    "    #print(len(df.texto3))\n",
    "    for t in row.texto3:\n",
    "        txt.append(stemmer.stem(t))\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"texto4\"] = df.apply(stemming,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63580"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = set([])\n",
    "\n",
    "for x in df[\"texto4\"]:\n",
    "    for y in x:\n",
    "        vocab.add(y)\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('E:/Code/prf-recursos-multas/dataset/multas_v3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separando base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = 'E:/Code/prf-recursos-multas/datasets/multas_v3.csv'\n",
    "\n",
    "df = pd.read_csv(df_path, encoding='utf-8',converters={\"texto3\": eval, \"texto4\": eval})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meio a meio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi = df[ df['parecer'] == 'I' ][0:173]\n",
    "dfd = df[ df['parecer'] == 'D' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([dfi,dfd])\n",
    "df = df2.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dobro de indeferimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi = df[ df['parecer'] == 'I' ][0:173*2]\n",
    "dfd = df[ df['parecer'] == 'D' ]\n",
    "df2 = pd.concat([dfi,dfd])\n",
    "df = df2.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separando dataset (80% treino & 20% teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "train_num = int(df.shape[0]*0.8)\n",
    "test_num = int(df.shape[0]*0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TokenizaÃ§Ã£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcula os codigos de multa mais relevantes\n",
    "\n",
    "freq2 = {}\n",
    "\n",
    "qtd = 0\n",
    "\n",
    "multa_qtd = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if not row.cod_multa in freq2:\n",
    "        freq2[row.cod_multa] = 1\n",
    "    else:\n",
    "        freq2[row.cod_multa] += 1\n",
    "\n",
    "for k in freq2.items():\n",
    "    if (k[1] >= qtd):\n",
    "        multa_qtd += k[1]\n",
    "\n",
    "# calcula a qtd de palavras totais\n",
    "\n",
    "freq3 = {}\n",
    "\n",
    "qtd = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if freq2[row.cod_multa] >= qtd:\n",
    "        for x in row.texto4:\n",
    "            \n",
    "            if not x in freq3:\n",
    "                freq3[x] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['arquivo', 'parecer', 'cod_multa']\n",
    "for x in freq3.items():\n",
    "    cols.append(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_zeros(qtd):\n",
    "    l = []\n",
    "    for x in range(0,qtd):\n",
    "        l.append(0)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = list_of_zeros(len(cols)-3)\n",
    "\n",
    "bow_rows = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if freq2[row.cod_multa] >= qtd:\n",
    "        r = [row.arquivo, row.parecer, row.cod_multa] + zeros\n",
    "        bow_rows.append(r)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bow = pd.DataFrame (bow_rows, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = 0\n",
    "for index, row in df.iterrows():\n",
    "    if freq2[row.cod_multa] >= qtd:\n",
    "        for x in row.texto4:\n",
    "            df_bow.loc[aux,x] += 1\n",
    "        aux += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bow = df_bow[ (df_bow.parecer == 'D') | (df_bow.parecer == 'I')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_to_int = {}\n",
    "\n",
    "aux = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if freq2[row.cod_multa] >= qtd:\n",
    "        if not row.cod_multa in cod_to_int:\n",
    "            cod_to_int[row.cod_multa] = aux\n",
    "            aux += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cod_to_int(row):\n",
    "    return cod_to_int[row.cod_multa]\n",
    "\n",
    "df_bow['cod_multa'] = df_bow.apply(convert_cod_to_int, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_par_to_int(row):\n",
    "    if (row.parecer == 'D'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df_bow['parecer'] = df_bow.apply(convert_par_to_int, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arquivo</th>\n",
       "      <th>parecer</th>\n",
       "      <th>cod_multa</th>\n",
       "      <th>ministeri</th>\n",
       "      <th>justig</th>\n",
       "      <th>departament</th>\n",
       "      <th>polic</th>\n",
       "      <th>rodovi</th>\n",
       "      <th>feder</th>\n",
       "      <th>superintendenc</th>\n",
       "      <th>...</th>\n",
       "      <th>infragaoq</th>\n",
       "      <th>sider</th>\n",
       "      <th>ovou</th>\n",
       "      <th>lentida</th>\n",
       "      <th>injustigas</th>\n",
       "      <th>infragdonenhumaprovatestemunh</th>\n",
       "      <th>daadministraca</th>\n",
       "      <th>constatacgd</th>\n",
       "      <th>aorecorrerapresent</th>\n",
       "      <th>wlegit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEI_08664.004601_2018_27_text</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEI_08664.006167_2018_10_text</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEI_08664.006401_2018_17_text</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEI_08664011448201894_text</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEI_08664.003985_2018_61_text</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>SEI_08664.000255_2018_16_text</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>SEI_08664011242201864_text</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>SEI_08664010373201824_text</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>SEI_08650.008641_2021_01</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>SEI_08664.006283_2018_39_text</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>519 rows Ã— 40312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           arquivo  parecer  cod_multa  ministeri  justig  \\\n",
       "0    SEI_08664.004601_2018_27_text        0          0          1       1   \n",
       "1    SEI_08664.006167_2018_10_text        0          1          0       0   \n",
       "2    SEI_08664.006401_2018_17_text        0          2          0       0   \n",
       "3       SEI_08664011448201894_text        1          3          6       0   \n",
       "4    SEI_08664.003985_2018_61_text        0          4          0       0   \n",
       "..                             ...      ...        ...        ...     ...   \n",
       "514  SEI_08664.000255_2018_16_text        0         49          0       0   \n",
       "515     SEI_08664011242201864_text        0          3          5       1   \n",
       "516     SEI_08664010373201824_text        0         17          7       0   \n",
       "517       SEI_08650.008641_2021_01        0          9          0       0   \n",
       "518  SEI_08664.006283_2018_39_text        0          4          0       1   \n",
       "\n",
       "     departament  polic  rodovi  feder  superintendenc  ...  infragaoq  sider  \\\n",
       "0              1      1       1      3               1  ...          0      0   \n",
       "1              1      2       2      6               0  ...          0      0   \n",
       "2              0      2       1      1               0  ...          0      0   \n",
       "3              3     15      11     14               3  ...          0      0   \n",
       "4              1      1       1      2               0  ...          0      0   \n",
       "..           ...    ...     ...    ...             ...  ...        ...    ...   \n",
       "514            1      0       0      1               0  ...          0      0   \n",
       "515            4     14      11     13               2  ...          0      0   \n",
       "516            3     14      12     15               3  ...          0      0   \n",
       "517            0      0       0      1               0  ...          0      0   \n",
       "518            0      1       1      1               0  ...          1      1   \n",
       "\n",
       "     ovou  lentida  injustigas  infragdonenhumaprovatestemunh  daadministraca  \\\n",
       "0       0        0           0                              0               0   \n",
       "1       0        0           0                              0               0   \n",
       "2       0        0           0                              0               0   \n",
       "3       0        0           0                              0               0   \n",
       "4       0        0           0                              0               0   \n",
       "..    ...      ...         ...                            ...             ...   \n",
       "514     0        0           0                              0               0   \n",
       "515     0        0           0                              0               0   \n",
       "516     0        0           0                              0               0   \n",
       "517     0        0           0                              0               0   \n",
       "518     1        1           1                              1               1   \n",
       "\n",
       "     constatacgd  aorecorrerapresent  wlegit  \n",
       "0              0                   0       0  \n",
       "1              0                   0       0  \n",
       "2              0                   0       0  \n",
       "3              0                   0       0  \n",
       "4              0                   0       0  \n",
       "..           ...                 ...     ...  \n",
       "514            0                   0       0  \n",
       "515            0                   0       0  \n",
       "516            0                   0       0  \n",
       "517            0                   0       0  \n",
       "518            1                   1       1  \n",
       "\n",
       "[519 rows x 40312 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_bow.to_csv('E:/Code/prf-recursos-multas/dataset/multas_bow_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ClassificaÃ§Ã£o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ministeri</th>\n",
       "      <th>justig</th>\n",
       "      <th>departament</th>\n",
       "      <th>polic</th>\n",
       "      <th>rodovi</th>\n",
       "      <th>feder</th>\n",
       "      <th>superintendenc</th>\n",
       "      <th>regionalrn</th>\n",
       "      <th>requer</th>\n",
       "      <th>pedr</th>\n",
       "      <th>...</th>\n",
       "      <th>infragaoq</th>\n",
       "      <th>sider</th>\n",
       "      <th>ovou</th>\n",
       "      <th>lentida</th>\n",
       "      <th>injustigas</th>\n",
       "      <th>infragdonenhumaprovatestemunh</th>\n",
       "      <th>daadministraca</th>\n",
       "      <th>constatacgd</th>\n",
       "      <th>aorecorrerapresent</th>\n",
       "      <th>wlegit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>519 rows Ã— 40309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ministeri  justig  departament  polic  rodovi  feder  superintendenc  \\\n",
       "0          1.0     1.0          1.0    1.0     1.0    3.0             1.0   \n",
       "1          0.0     0.0          1.0    2.0     2.0    6.0             0.0   \n",
       "2          0.0     0.0          0.0    2.0     1.0    1.0             0.0   \n",
       "3          6.0     0.0          3.0   15.0    11.0   14.0             3.0   \n",
       "4          0.0     0.0          1.0    1.0     1.0    2.0             0.0   \n",
       "..         ...     ...          ...    ...     ...    ...             ...   \n",
       "514        0.0     0.0          1.0    0.0     0.0    1.0             0.0   \n",
       "515        5.0     1.0          4.0   14.0    11.0   13.0             2.0   \n",
       "516        7.0     0.0          3.0   14.0    12.0   15.0             3.0   \n",
       "517        0.0     0.0          0.0    0.0     0.0    1.0             0.0   \n",
       "518        0.0     1.0          0.0    1.0     1.0    1.0             0.0   \n",
       "\n",
       "     regionalrn  requer  pedr  ...  infragaoq  sider  ovou  lentida  \\\n",
       "0           1.0     4.0   1.0  ...        0.0    0.0   0.0      0.0   \n",
       "1           0.0     4.0   0.0  ...        0.0    0.0   0.0      0.0   \n",
       "2           0.0     0.0   0.0  ...        0.0    0.0   0.0      0.0   \n",
       "3           0.0    14.0   0.0  ...        0.0    0.0   0.0      0.0   \n",
       "4           0.0     1.0   1.0  ...        0.0    0.0   0.0      0.0   \n",
       "..          ...     ...   ...  ...        ...    ...   ...      ...   \n",
       "514         0.0     6.0   0.0  ...        0.0    0.0   0.0      0.0   \n",
       "515         0.0    17.0   0.0  ...        0.0    0.0   0.0      0.0   \n",
       "516         0.0    17.0   0.0  ...        0.0    0.0   0.0      0.0   \n",
       "517         0.0     4.0   0.0  ...        0.0    0.0   0.0      0.0   \n",
       "518         0.0     4.0   0.0  ...        1.0    1.0   1.0      1.0   \n",
       "\n",
       "     injustigas  infragdonenhumaprovatestemunh  daadministraca  constatacgd  \\\n",
       "0           0.0                            0.0             0.0          0.0   \n",
       "1           0.0                            0.0             0.0          0.0   \n",
       "2           0.0                            0.0             0.0          0.0   \n",
       "3           0.0                            0.0             0.0          0.0   \n",
       "4           0.0                            0.0             0.0          0.0   \n",
       "..          ...                            ...             ...          ...   \n",
       "514         0.0                            0.0             0.0          0.0   \n",
       "515         0.0                            0.0             0.0          0.0   \n",
       "516         0.0                            0.0             0.0          0.0   \n",
       "517         0.0                            0.0             0.0          0.0   \n",
       "518         1.0                            1.0             1.0          1.0   \n",
       "\n",
       "     aorecorrerapresent  wlegit  \n",
       "0                   0.0     0.0  \n",
       "1                   0.0     0.0  \n",
       "2                   0.0     0.0  \n",
       "3                   0.0     0.0  \n",
       "4                   0.0     0.0  \n",
       "..                  ...     ...  \n",
       "514                 0.0     0.0  \n",
       "515                 0.0     0.0  \n",
       "516                 0.0     0.0  \n",
       "517                 0.0     0.0  \n",
       "518                 1.0     1.0  \n",
       "\n",
       "[519 rows x 40309 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf = df_bow.copy()\n",
    "\n",
    "df_bow_target_parecer = df_tfidf['parecer']\n",
    "\n",
    "df_tfidf = df_tfidf.drop(['arquivo', 'parecer', 'cod_multa'],axis=1)\n",
    "df_tfidf *= 1.0\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = df_tfidf.shape[0] * 1.0\n",
    "aux = df_tfidf.columns\n",
    "\n",
    "\n",
    "dft = {}\n",
    "for w in aux:\n",
    "    x = df_tfidf[df_tfidf[w] > 0].shape[0]\n",
    "    if (x == 0):\n",
    "        x = 1.0\n",
    "    dft[w] = math.log2(M/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_tfidf.iterrows():\n",
    "    cnt = 0\n",
    "    for w in aux:\n",
    "        if (row[w]>0.0):\n",
    "            cnt += 1\n",
    "    for w in aux:\n",
    "        row[w] = (row[w]/cnt) * dft[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ministeri</th>\n",
       "      <th>justig</th>\n",
       "      <th>departament</th>\n",
       "      <th>polic</th>\n",
       "      <th>rodovi</th>\n",
       "      <th>feder</th>\n",
       "      <th>superintendenc</th>\n",
       "      <th>regionalrn</th>\n",
       "      <th>requer</th>\n",
       "      <th>pedr</th>\n",
       "      <th>...</th>\n",
       "      <th>infragaoq</th>\n",
       "      <th>sider</th>\n",
       "      <th>ovou</th>\n",
       "      <th>lentida</th>\n",
       "      <th>injustigas</th>\n",
       "      <th>infragdonenhumaprovatestemunh</th>\n",
       "      <th>daadministraca</th>\n",
       "      <th>constatacgd</th>\n",
       "      <th>aorecorrerapresent</th>\n",
       "      <th>wlegit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002190</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.008275</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.007544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>0.005652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>0.001759</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>0.003855</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.009711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.007018</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0.008239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>0.004294</td>\n",
       "      <td>0.004949</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01658</td>\n",
       "      <td>0.01658</td>\n",
       "      <td>0.01658</td>\n",
       "      <td>0.01658</td>\n",
       "      <td>0.01658</td>\n",
       "      <td>0.01658</td>\n",
       "      <td>0.01658</td>\n",
       "      <td>0.01658</td>\n",
       "      <td>0.01658</td>\n",
       "      <td>0.01658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>519 rows Ã— 40309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ministeri    justig  departament     polic    rodovi     feder  \\\n",
       "0     0.002190  0.004715     0.001451  0.000571  0.000767  0.001332   \n",
       "1     0.000000  0.000000     0.003077  0.002421  0.003255  0.005652   \n",
       "2     0.000000  0.000000     0.000000  0.002616  0.001759  0.001018   \n",
       "3     0.006002  0.000000     0.001988  0.003909  0.003855  0.002840   \n",
       "4     0.000000  0.000000     0.001868  0.000735  0.000988  0.001143   \n",
       "..         ...       ...          ...       ...       ...       ...   \n",
       "514   0.000000  0.000000     0.002702  0.000000  0.000000  0.000827   \n",
       "515   0.007018  0.003022     0.003719  0.005120  0.005409  0.003700   \n",
       "516   0.008239  0.000000     0.002339  0.004294  0.004949  0.003580   \n",
       "517   0.000000  0.000000     0.000000  0.000000  0.000000  0.000548   \n",
       "518   0.000000  0.005166     0.000000  0.000625  0.000841  0.000487   \n",
       "\n",
       "     superintendenc  regionalrn    requer      pedr  ...  infragaoq    sider  \\\n",
       "0          0.001991    0.008275  0.002817  0.007544  ...    0.00000  0.00000   \n",
       "1          0.000000    0.000000  0.005974  0.000000  ...    0.00000  0.00000   \n",
       "2          0.000000    0.000000  0.000000  0.000000  ...    0.00000  0.00000   \n",
       "3          0.002728    0.000000  0.004502  0.000000  ...    0.00000  0.00000   \n",
       "4          0.000000    0.000000  0.000906  0.009711  ...    0.00000  0.00000   \n",
       "..              ...         ...       ...       ...  ...        ...      ...   \n",
       "514        0.000000    0.000000  0.007869  0.000000  ...    0.00000  0.00000   \n",
       "515        0.002552    0.000000  0.007672  0.000000  ...    0.00000  0.00000   \n",
       "516        0.003210    0.000000  0.006433  0.000000  ...    0.00000  0.00000   \n",
       "517        0.000000    0.000000  0.003476  0.000000  ...    0.00000  0.00000   \n",
       "518        0.000000    0.000000  0.003086  0.000000  ...    0.01658  0.01658   \n",
       "\n",
       "        ovou  lentida  injustigas  infragdonenhumaprovatestemunh  \\\n",
       "0    0.00000  0.00000     0.00000                        0.00000   \n",
       "1    0.00000  0.00000     0.00000                        0.00000   \n",
       "2    0.00000  0.00000     0.00000                        0.00000   \n",
       "3    0.00000  0.00000     0.00000                        0.00000   \n",
       "4    0.00000  0.00000     0.00000                        0.00000   \n",
       "..       ...      ...         ...                            ...   \n",
       "514  0.00000  0.00000     0.00000                        0.00000   \n",
       "515  0.00000  0.00000     0.00000                        0.00000   \n",
       "516  0.00000  0.00000     0.00000                        0.00000   \n",
       "517  0.00000  0.00000     0.00000                        0.00000   \n",
       "518  0.01658  0.01658     0.01658                        0.01658   \n",
       "\n",
       "     daadministraca  constatacgd  aorecorrerapresent   wlegit  \n",
       "0           0.00000      0.00000             0.00000  0.00000  \n",
       "1           0.00000      0.00000             0.00000  0.00000  \n",
       "2           0.00000      0.00000             0.00000  0.00000  \n",
       "3           0.00000      0.00000             0.00000  0.00000  \n",
       "4           0.00000      0.00000             0.00000  0.00000  \n",
       "..              ...          ...                 ...      ...  \n",
       "514         0.00000      0.00000             0.00000  0.00000  \n",
       "515         0.00000      0.00000             0.00000  0.00000  \n",
       "516         0.00000      0.00000             0.00000  0.00000  \n",
       "517         0.00000      0.00000             0.00000  0.00000  \n",
       "518         0.01658      0.01658             0.01658  0.01658  \n",
       "\n",
       "[519 rows x 40309 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tfidf.to_csv('E:/Code/prf-recursos-multas/dataset/multas_tfidf_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ClassificaÃ§Ã£o com TF-IDF (Por Deferimento)\n",
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_tfidf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-21c3d6586b7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_bow_target_parecer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_tfidf' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_tfidf, df_bow_target_parecer, test_size=0.2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8365384615384616\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88        67\n",
      "           1       0.88      0.62      0.73        37\n",
      "\n",
      "    accuracy                           0.84       104\n",
      "   macro avg       0.85      0.79      0.81       104\n",
      "weighted avg       0.84      0.84      0.83       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.252 (+/-0.007) for {'C': 1, 'kernel': 'linear'}\n",
      "0.684 (+/-0.123) for {'C': 10, 'kernel': 'linear'}\n",
      "0.723 (+/-0.035) for {'C': 100, 'kernel': 'linear'}\n",
      "0.711 (+/-0.083) for {'C': 1000, 'kernel': 'linear'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.86      0.75        36\n",
      "           1       0.78      0.53      0.63        34\n",
      "\n",
      "    accuracy                           0.70        70\n",
      "   macro avg       0.72      0.70      0.69        70\n",
      "weighted avg       0.72      0.70      0.69        70\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tuned_parameters = [{'kernel': ['rbf'], 'gamma': [0.001, 0.0001], 'C': [1, 10, 100, 1000]},\n",
    "#                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "tuned_parameters = [{'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "scores = ['precision']\n",
    "\n",
    "for score in scores:\n",
    "    clf = GridSearchCV(SVC(), tuned_parameters, scoring='%s_macro' % score)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = 'E:/Code/prf-recursos-multas/datasets/multas_v3.csv'\n",
    "\n",
    "df = pd.read_csv(df_path, encoding='utf-8',converters={\"texto3\": eval, \"texto4\": eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I    960\n",
       "D    173\n",
       "A     13\n",
       "N      2\n",
       "Name: parecer, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.parecer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[ (df.parecer == 'D') | (df.parecer == 'I')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(row):\n",
    "    txt = \"\"\n",
    "    for t in row[\"texto4\"]:\n",
    "        txt += t + \" \"\n",
    "    return txt\n",
    "df[\"texto5\"] = df.apply(test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "xxxx=200\n",
    "\n",
    "tokenizer = Tokenizer(nb_words=xxxx, lower=True,split=' ')\n",
    "tokenizer.fit_on_texts(df['texto5'].values)\n",
    "#print(tokenizer.word_index)  # To see the dicstionary\n",
    "X = tokenizer.texts_to_sequences(df['texto5'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3786"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "embed_dim = 128\n",
    "lstm_out = 300\n",
    "batch_size = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(xxxx, embed_dim,input_length = X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.1))\n",
    "model.add(LSTM(units=lstm_out, dropout = 0.1, recurrent_dropout = 0.1))\n",
    "#model.add(LSTM(units=lstm_out)\n",
    "##model.add(Dropout(0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 471s 52s/step - loss: 0.6782 - accuracy: 0.5615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2118c1ea640>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.get_dummies(df['parecer']).values\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X,Y,  test_size=0.2, seed = 1, stratify=Y)\n",
    "#X_train, X_valid, Y_train, Y_valid = train_test_split(X,Y,  test_size=0.2,shuffle=False)\n",
    "\n",
    "#Here we train the Network.\n",
    "\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score,acc = model.evaluate(X_valid, Y_valid, verbose = 2, batch_size = batch_size)\n",
    "print(\"Score: %.2f\" % (score))\n",
    "print(\"Validation Accuracy: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(x):\n",
    "    rtn = []\n",
    "    for i in x:\n",
    "        if i[0] > i[1]:\n",
    "            rtn.append(0)\n",
    "        else:\n",
    "            rtn.append(1)\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = binarize(Y_pred)\n",
    "y_true = binarize(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = 'E:/Code/prf-recursos-multas/dataset/multas_v3.csv'\n",
    "df = pd.read_csv(df_path, encoding='utf-8',converters={\"texto3\": eval, \"texto4\": eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1148, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I    960\n",
       "D    173\n",
       "A     13\n",
       "N      2\n",
       "Name: parecer, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['parecer'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pesquisar por**\n",
    "\n",
    "**split_test_train com o parametro stratify**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definindo as funÃ§Ãµes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_zeros(qtd):\n",
    "    l = []\n",
    "    for x in range(0,qtd):\n",
    "        l.append(0)\n",
    "    return l\n",
    "\n",
    "cod_to_int = {}\n",
    "\n",
    "def convert_cod_to_int(row):\n",
    "    global cod_to_int\n",
    "    return cod_to_int[row.cod_multa]\n",
    "\n",
    "def convert_par_to_int(row):\n",
    "    if (row.parecer == 'D'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_bow_df(df):\n",
    "    \n",
    "    freq2 = {}\n",
    "\n",
    "    qtd = 0\n",
    "\n",
    "    multa_qtd = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if not row.cod_multa in freq2:\n",
    "            freq2[row.cod_multa] = 1\n",
    "        else:\n",
    "            freq2[row.cod_multa] += 1\n",
    "\n",
    "    for k in freq2.items():\n",
    "        if (k[1] >= qtd):\n",
    "            multa_qtd += k[1]\n",
    "\n",
    "    # calcula a qtd de palavras totais\n",
    "\n",
    "    freq3 = {}\n",
    "\n",
    "    qtd = 0\n",
    "    \n",
    "\n",
    "    aux = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if freq2[row.cod_multa] >= qtd:\n",
    "            for x in row.texto4:\n",
    "\n",
    "                if not x in freq3:\n",
    "                    freq3[x] = 1\n",
    "\n",
    "    cols = ['arquivo', 'parecer', 'cod_multa']\n",
    "    for x in freq3.items():\n",
    "        cols.append(x[0])\n",
    "\n",
    "    zeros = list_of_zeros(len(cols)-3)\n",
    "\n",
    "    bow_rows = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if freq2[row.cod_multa] >= qtd:\n",
    "            r = [row.arquivo, row.parecer, row.cod_multa] + zeros\n",
    "            bow_rows.append(r)\n",
    "\n",
    "    df_bow = pd.DataFrame (bow_rows, columns = cols)\n",
    "    aux = 0\n",
    "    for index, row in df.iterrows():\n",
    "        if freq2[row.cod_multa] >= qtd:\n",
    "            for x in row.texto4:\n",
    "                df_bow.loc[aux,x] += 1\n",
    "            aux += 1\n",
    "    global cod_to_int\n",
    "    cod_to_int = {}\n",
    "\n",
    "    aux = 0\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        if freq2[row.cod_multa] >= qtd:\n",
    "            if not row.cod_multa in cod_to_int:\n",
    "                cod_to_int[row.cod_multa] = aux\n",
    "                aux += 1\n",
    "                \n",
    "    df_bow['cod_multa'] = df_bow.apply(convert_cod_to_int, axis=1)\n",
    "    df_bow['parecer'] = df_bow.apply(convert_par_to_int, axis=1)\n",
    "\n",
    "    return df_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_tfidf_df(df_bow):\n",
    "    df_tfidf = df_bow.copy()\n",
    "\n",
    "    df_bow_target_parecer = df_tfidf['parecer']\n",
    "\n",
    "    df_tfidf = df_tfidf.drop(['arquivo', 'parecer', 'cod_multa'],axis=1)\n",
    "    df_tfidf *= 1.0\n",
    "    df_tfidf\n",
    "\n",
    "    M = df_tfidf.shape[0] * 1.0\n",
    "    aux = df_tfidf.columns\n",
    "\n",
    "\n",
    "    dft = {}\n",
    "    for w in aux:\n",
    "        x = df_tfidf[df_tfidf[w] > 0].shape[0]\n",
    "        if (x == 0):\n",
    "            x = 1.0\n",
    "        dft[w] = math.log2(M/x)\n",
    "\n",
    "    for index, row in df_tfidf.iterrows():\n",
    "        cnt = 0\n",
    "        for w in aux:\n",
    "            if (row[w]>0.0):\n",
    "                cnt += 1\n",
    "        for w in aux:\n",
    "            row[w] = (row[w]/cnt) * dft[w]\n",
    "\n",
    "    return df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(row):\n",
    "    txt = \"\"\n",
    "    for t in row[\"texto4\"]:\n",
    "        txt += t + \" \"\n",
    "    return txt\n",
    "\n",
    "def binarize(x):\n",
    "    rtn = []\n",
    "    for i in x:\n",
    "        if i[0] > i[1]:\n",
    "            rtn.append(0)\n",
    "        else:\n",
    "            rtn.append(1)\n",
    "    return rtn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_loop = 20\n",
    "\n",
    "def pipeline(df, df_bow, df_tfidf):\n",
    "    df_bow_data = df_bow.drop(['arquivo', 'parecer', 'cod_multa'], axis=1)\n",
    "    df_bow_target_multa = df_bow['cod_multa']\n",
    "    df_bow_target_parecer = df_bow['parecer']\n",
    "    #-------------------------------------\n",
    "    print(\"Naive-bayes + BOW\")\n",
    "    \n",
    "\n",
    "    for i in range (0,pl_loop):\n",
    "        print(\">>\" + str(i))\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df_bow_data, df_bow_target_parecer, test_size=0.2)\n",
    "        \n",
    "        clf = MultinomialNB()\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    \n",
    "    #-------------------------------------\n",
    "    print(\"SVM + BOW\")\n",
    "    for i in range (0,pl_loop):\n",
    "        print(\">>\" + str(i))\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df_bow_data, df_bow_target_parecer, test_size=0.2)\n",
    "        \n",
    "        clf = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    #-------------------------------------\n",
    "    \n",
    "    print(\"Naive-bayes + TFIDF\")\n",
    "    for i in range (0,pl_loop):\n",
    "        print(\">>\" + str(i))\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df_tfidf, df_bow_target_parecer, test_size=0.2)\n",
    "        \n",
    "        clf = MultinomialNB()\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    #-------------------------------------\n",
    "    print(\"SVM + TFIDF\")\n",
    "\n",
    "    \n",
    "    for i in range (0,pl_loop):\n",
    "        print(\">>\" + str(i))\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df_tfidf, df_bow_target_parecer, test_size=0.2)\n",
    "        \n",
    "        clf = svm.SVC(kernel='linear', C=100)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    #-------------------------------------\n",
    "    print(\"LSTM + Word2Vec\")\n",
    "    \n",
    "    df = df[ (df.parecer == 'D') | (df.parecer == 'I')]\n",
    "\n",
    "    df[\"texto5\"] = df.apply(test,axis=1)\n",
    "\n",
    "    xxxx=200\n",
    "\n",
    "    tokenizer = Tokenizer(nb_words=xxxx, lower=True,split=' ')\n",
    "    tokenizer.fit_on_texts(df['texto5'].values)\n",
    "    #print(tokenizer.word_index)  # To see the dicstionary\n",
    "    X = tokenizer.texts_to_sequences(df['texto5'].values)\n",
    "    X = pad_sequences(X)\n",
    "\n",
    "    embed_dim = 128\n",
    "    lstm_out = 300\n",
    "    batch_size = 32\n",
    "\n",
    "    \n",
    "\n",
    "    Y = pd.get_dummies(df['parecer']).values\n",
    "    #X_train, X_valid, Y_train, Y_valid = train_test_split(X,Y,  test_size=0.2, seed = 1, stratify=Y)\n",
    "    X_train, X_valid, Y_train, Y_valid = train_test_split(X,Y,  test_size=0.2,shuffle=False)\n",
    "\n",
    "    #Here we train the Network.\n",
    "    for i in range (0,pl_loop):\n",
    "        print(\">>\" + str(i))\n",
    "        X_train, X_valid, Y_train, Y_valid = train_test_split(X,Y,  test_size=0.2)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Embedding(xxxx, embed_dim,input_length = X.shape[1]))\n",
    "        model.add(SpatialDropout1D(0.1))\n",
    "        model.add(LSTM(units=lstm_out, dropout = 0.1, recurrent_dropout = 0.1))\n",
    "        #model.add(LSTM(units=lstm_out)\n",
    "        ##model.add(Dropout(0.2))\n",
    "        model.add(Dense(2,activation='softmax'))\n",
    "        model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "        print(model.summary())\n",
    "        \n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        Y_pred = model.predict(X_valid)\n",
    "\n",
    "        y_pred = binarize(Y_pred)\n",
    "        y_true = binarize(Y_valid)\n",
    "\n",
    "        print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de dados inteira"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = 'E:/Code/prf-recursos-multas/datasets/multas_v3.csv'\n",
    "df = pd.read_csv(df_path, encoding='utf-8',converters={\"texto3\": eval, \"texto4\": eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bow = gerar_bow_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf = gerar_tfidf_df(df_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-bayes + BOW\n",
      ">>0\n",
      "Accuracy: 0.8695652173913043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.93       192\n",
      "           1       0.72      0.34      0.46        38\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.80      0.66      0.70       230\n",
      "weighted avg       0.86      0.87      0.85       230\n",
      "\n",
      ">>1\n",
      "Accuracy: 0.8739130434782608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       194\n",
      "           1       0.71      0.33      0.45        36\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.80      0.65      0.69       230\n",
      "weighted avg       0.86      0.87      0.85       230\n",
      "\n",
      ">>2\n",
      "Accuracy: 0.8695652173913043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       198\n",
      "           1       0.56      0.28      0.38        32\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.73      0.62      0.65       230\n",
      "weighted avg       0.85      0.87      0.85       230\n",
      "\n",
      ">>3\n",
      "Accuracy: 0.8739130434782608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       197\n",
      "           1       0.62      0.30      0.41        33\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.76      0.64      0.67       230\n",
      "weighted avg       0.85      0.87      0.85       230\n",
      "\n",
      ">>4\n",
      "Accuracy: 0.9130434782608695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95       203\n",
      "           1       0.82      0.33      0.47        27\n",
      "\n",
      "    accuracy                           0.91       230\n",
      "   macro avg       0.87      0.66      0.71       230\n",
      "weighted avg       0.91      0.91      0.90       230\n",
      "\n",
      ">>5\n",
      "Accuracy: 0.8782608695652174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       193\n",
      "           1       0.85      0.30      0.44        37\n",
      "\n",
      "    accuracy                           0.88       230\n",
      "   macro avg       0.86      0.64      0.69       230\n",
      "weighted avg       0.87      0.88      0.85       230\n",
      "\n",
      ">>6\n",
      "Accuracy: 0.8782608695652174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       200\n",
      "           1       0.58      0.23      0.33        30\n",
      "\n",
      "    accuracy                           0.88       230\n",
      "   macro avg       0.74      0.60      0.63       230\n",
      "weighted avg       0.85      0.88      0.85       230\n",
      "\n",
      ">>7\n",
      "Accuracy: 0.9043478260869565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95       196\n",
      "           1       0.88      0.41      0.56        34\n",
      "\n",
      "    accuracy                           0.90       230\n",
      "   macro avg       0.89      0.70      0.75       230\n",
      "weighted avg       0.90      0.90      0.89       230\n",
      "\n",
      ">>8\n",
      "Accuracy: 0.8913043478260869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       197\n",
      "           1       0.79      0.33      0.47        33\n",
      "\n",
      "    accuracy                           0.89       230\n",
      "   macro avg       0.84      0.66      0.70       230\n",
      "weighted avg       0.88      0.89      0.87       230\n",
      "\n",
      ">>9\n",
      "Accuracy: 0.908695652173913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       206\n",
      "           1       0.64      0.29      0.40        24\n",
      "\n",
      "    accuracy                           0.91       230\n",
      "   macro avg       0.78      0.64      0.68       230\n",
      "weighted avg       0.89      0.91      0.89       230\n",
      "\n",
      ">>10\n",
      "Accuracy: 0.8913043478260869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       200\n",
      "           1       0.73      0.27      0.39        30\n",
      "\n",
      "    accuracy                           0.89       230\n",
      "   macro avg       0.81      0.63      0.67       230\n",
      "weighted avg       0.88      0.89      0.87       230\n",
      "\n",
      ">>11\n",
      "Accuracy: 0.8652173913043478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92       191\n",
      "           1       0.83      0.26      0.39        39\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.85      0.62      0.66       230\n",
      "weighted avg       0.86      0.87      0.83       230\n",
      "\n",
      ">>12\n",
      "Accuracy: 0.8913043478260869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       196\n",
      "           1       1.00      0.26      0.42        34\n",
      "\n",
      "    accuracy                           0.89       230\n",
      "   macro avg       0.94      0.63      0.68       230\n",
      "weighted avg       0.90      0.89      0.86       230\n",
      "\n",
      ">>13\n",
      "Accuracy: 0.8869565217391304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94       198\n",
      "           1       0.69      0.34      0.46        32\n",
      "\n",
      "    accuracy                           0.89       230\n",
      "   macro avg       0.79      0.66      0.70       230\n",
      "weighted avg       0.87      0.89      0.87       230\n",
      "\n",
      ">>14\n",
      "Accuracy: 0.8478260869565217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.91       189\n",
      "           1       0.71      0.24      0.36        41\n",
      "\n",
      "    accuracy                           0.85       230\n",
      "   macro avg       0.79      0.61      0.64       230\n",
      "weighted avg       0.83      0.85      0.82       230\n",
      "\n",
      ">>15\n",
      "Accuracy: 0.8739130434782608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93       196\n",
      "           1       0.73      0.24      0.36        34\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.80      0.61      0.64       230\n",
      "weighted avg       0.86      0.87      0.85       230\n",
      "\n",
      ">>16\n",
      "Accuracy: 0.8565217391304348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       193\n",
      "           1       0.64      0.24      0.35        37\n",
      "\n",
      "    accuracy                           0.86       230\n",
      "   macro avg       0.76      0.61      0.64       230\n",
      "weighted avg       0.83      0.86      0.83       230\n",
      "\n",
      ">>17\n",
      "Accuracy: 0.8478260869565217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91       191\n",
      "           1       0.62      0.26      0.36        39\n",
      "\n",
      "    accuracy                           0.85       230\n",
      "   macro avg       0.74      0.61      0.64       230\n",
      "weighted avg       0.82      0.85      0.82       230\n",
      "\n",
      ">>18\n",
      "Accuracy: 0.8782608695652174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93       198\n",
      "           1       0.64      0.28      0.39        32\n",
      "\n",
      "    accuracy                           0.88       230\n",
      "   macro avg       0.77      0.63      0.66       230\n",
      "weighted avg       0.86      0.88      0.86       230\n",
      "\n",
      ">>19\n",
      "Accuracy: 0.8739130434782608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93       197\n",
      "           1       0.70      0.21      0.33        33\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.79      0.60      0.63       230\n",
      "weighted avg       0.86      0.87      0.84       230\n",
      "\n",
      "SVM + BOW\n",
      ">>0\n",
      "Accuracy: 0.8608695652173913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       194\n",
      "           1       0.58      0.42      0.48        36\n",
      "\n",
      "    accuracy                           0.86       230\n",
      "   macro avg       0.74      0.68      0.70       230\n",
      "weighted avg       0.85      0.86      0.85       230\n",
      "\n",
      ">>1\n",
      "Accuracy: 0.8652173913043478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92       202\n",
      "           1       0.44      0.43      0.44        28\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.68      0.68      0.68       230\n",
      "weighted avg       0.86      0.87      0.86       230\n",
      "\n",
      ">>2\n",
      "Accuracy: 0.8695652173913043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92       195\n",
      "           1       0.58      0.54      0.56        35\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.75      0.74      0.74       230\n",
      "weighted avg       0.87      0.87      0.87       230\n",
      "\n",
      ">>3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8652173913043478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92       200\n",
      "           1       0.48      0.43      0.46        30\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.70      0.68      0.69       230\n",
      "weighted avg       0.86      0.87      0.86       230\n",
      "\n",
      ">>4\n",
      "Accuracy: 0.8608695652173913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92       198\n",
      "           1       0.50      0.53      0.52        32\n",
      "\n",
      "    accuracy                           0.86       230\n",
      "   macro avg       0.71      0.72      0.72       230\n",
      "weighted avg       0.86      0.86      0.86       230\n",
      "\n",
      ">>5\n",
      "Accuracy: 0.8608695652173913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       191\n",
      "           1       0.60      0.54      0.57        39\n",
      "\n",
      "    accuracy                           0.86       230\n",
      "   macro avg       0.75      0.73      0.74       230\n",
      "weighted avg       0.86      0.86      0.86       230\n",
      "\n",
      ">>6\n",
      "Accuracy: 0.8869565217391304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       200\n",
      "           1       0.56      0.60      0.58        30\n",
      "\n",
      "    accuracy                           0.89       230\n",
      "   macro avg       0.75      0.77      0.76       230\n",
      "weighted avg       0.89      0.89      0.89       230\n",
      "\n",
      ">>7\n",
      "Accuracy: 0.8782608695652174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       197\n",
      "           1       0.59      0.48      0.53        33\n",
      "\n",
      "    accuracy                           0.88       230\n",
      "   macro avg       0.75      0.71      0.73       230\n",
      "weighted avg       0.87      0.88      0.87       230\n",
      "\n",
      ">>8\n",
      "Accuracy: 0.8695652173913043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.92       199\n",
      "           1       0.52      0.55      0.53        31\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.72      0.73      0.73       230\n",
      "weighted avg       0.87      0.87      0.87       230\n",
      "\n",
      ">>9\n",
      "Accuracy: 0.8782608695652174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       196\n",
      "           1       0.62      0.47      0.53        34\n",
      "\n",
      "    accuracy                           0.88       230\n",
      "   macro avg       0.76      0.71      0.73       230\n",
      "weighted avg       0.87      0.88      0.87       230\n",
      "\n",
      ">>10\n",
      "Accuracy: 0.8782608695652174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93       195\n",
      "           1       0.61      0.57      0.59        35\n",
      "\n",
      "    accuracy                           0.88       230\n",
      "   macro avg       0.76      0.75      0.76       230\n",
      "weighted avg       0.88      0.88      0.88       230\n",
      "\n",
      ">>11\n",
      "Accuracy: 0.8913043478260869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.94       194\n",
      "           1       0.68      0.58      0.63        36\n",
      "\n",
      "    accuracy                           0.89       230\n",
      "   macro avg       0.80      0.77      0.78       230\n",
      "weighted avg       0.89      0.89      0.89       230\n",
      "\n",
      ">>12\n",
      "Accuracy: 0.8826086956521739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93       192\n",
      "           1       0.67      0.58      0.62        38\n",
      "\n",
      "    accuracy                           0.88       230\n",
      "   macro avg       0.79      0.76      0.78       230\n",
      "weighted avg       0.88      0.88      0.88       230\n",
      "\n",
      ">>13\n",
      "Accuracy: 0.8391304347826087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.91       201\n",
      "           1       0.39      0.48      0.43        29\n",
      "\n",
      "    accuracy                           0.84       230\n",
      "   macro avg       0.66      0.69      0.67       230\n",
      "weighted avg       0.86      0.84      0.85       230\n",
      "\n",
      ">>14\n",
      "Accuracy: 0.8652173913043478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92       201\n",
      "           1       0.46      0.41      0.44        29\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.69      0.67      0.68       230\n",
      "weighted avg       0.86      0.87      0.86       230\n",
      "\n",
      ">>15\n",
      "Accuracy: 0.8652173913043478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       191\n",
      "           1       0.63      0.49      0.55        39\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.77      0.71      0.74       230\n",
      "weighted avg       0.85      0.87      0.86       230\n",
      "\n",
      ">>16\n",
      "Accuracy: 0.8391304347826087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91       195\n",
      "           1       0.47      0.40      0.43        35\n",
      "\n",
      "    accuracy                           0.84       230\n",
      "   macro avg       0.68      0.66      0.67       230\n",
      "weighted avg       0.83      0.84      0.83       230\n",
      "\n",
      ">>17\n",
      "Accuracy: 0.8391304347826087\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.91      0.90       192\n",
      "           1       0.51      0.47      0.49        38\n",
      "\n",
      "    accuracy                           0.84       230\n",
      "   macro avg       0.71      0.69      0.70       230\n",
      "weighted avg       0.83      0.84      0.84       230\n",
      "\n",
      ">>18\n",
      "Accuracy: 0.8608695652173913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.92       196\n",
      "           1       0.53      0.62      0.57        34\n",
      "\n",
      "    accuracy                           0.86       230\n",
      "   macro avg       0.73      0.76      0.74       230\n",
      "weighted avg       0.87      0.86      0.87       230\n",
      "\n",
      ">>19\n",
      "Accuracy: 0.8608695652173913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.92       202\n",
      "           1       0.41      0.32      0.36        28\n",
      "\n",
      "    accuracy                           0.86       230\n",
      "   macro avg       0.66      0.63      0.64       230\n",
      "weighted avg       0.85      0.86      0.85       230\n",
      "\n",
      "Naive-bayes + TFIDF\n",
      ">>0\n",
      "Accuracy: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95       207\n",
      "           1       0.00      0.00      0.00        23\n",
      "\n",
      "    accuracy                           0.90       230\n",
      "   macro avg       0.45      0.50      0.47       230\n",
      "weighted avg       0.81      0.90      0.85       230\n",
      "\n",
      ">>1\n",
      "Accuracy: 0.8913043478260869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       205\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.89       230\n",
      "   macro avg       0.45      0.50      0.47       230\n",
      "weighted avg       0.79      0.89      0.84       230\n",
      "\n",
      ">>2\n",
      "Accuracy: 0.8652173913043478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       199\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.43      0.50      0.46       230\n",
      "weighted avg       0.75      0.87      0.80       230\n",
      "\n",
      ">>3\n",
      "Accuracy: 0.8521739130434782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       196\n",
      "           1       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.85       230\n",
      "   macro avg       0.43      0.50      0.46       230\n",
      "weighted avg       0.73      0.85      0.78       230\n",
      "\n",
      ">>4\n",
      "Accuracy: 0.8478260869565217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       195\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.85       230\n",
      "   macro avg       0.42      0.50      0.46       230\n",
      "weighted avg       0.72      0.85      0.78       230\n",
      "\n",
      ">>5\n",
      "Accuracy: 0.8608695652173913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       198\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.86       230\n",
      "   macro avg       0.43      0.50      0.46       230\n",
      "weighted avg       0.74      0.86      0.80       230\n",
      "\n",
      ">>6\n",
      "Accuracy: 0.8782608695652174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94       202\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.88       230\n",
      "   macro avg       0.44      0.50      0.47       230\n",
      "weighted avg       0.77      0.88      0.82       230\n",
      "\n",
      ">>7\n",
      "Accuracy: 0.8478260869565217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       195\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.85       230\n",
      "   macro avg       0.42      0.50      0.46       230\n",
      "weighted avg       0.72      0.85      0.78       230\n",
      "\n",
      ">>8\n",
      "Accuracy: 0.8608695652173913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       198\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.86       230\n",
      "   macro avg       0.43      0.50      0.46       230\n",
      "weighted avg       0.74      0.86      0.80       230\n",
      "\n",
      ">>9\n",
      "Accuracy: 0.8652173913043478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       199\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.43      0.50      0.46       230\n",
      "weighted avg       0.75      0.87      0.80       230\n",
      "\n",
      ">>10\n",
      "Accuracy: 0.808695652173913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89       186\n",
      "           1       0.00      0.00      0.00        44\n",
      "\n",
      "    accuracy                           0.81       230\n",
      "   macro avg       0.40      0.50      0.45       230\n",
      "weighted avg       0.65      0.81      0.72       230\n",
      "\n",
      ">>11\n",
      "Accuracy: 0.8565217391304348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92       197\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.86       230\n",
      "   macro avg       0.43      0.50      0.46       230\n",
      "weighted avg       0.73      0.86      0.79       230\n",
      "\n",
      ">>12\n",
      "Accuracy: 0.8478260869565217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       195\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.85       230\n",
      "   macro avg       0.42      0.50      0.46       230\n",
      "weighted avg       0.72      0.85      0.78       230\n",
      "\n",
      ">>13\n",
      "Accuracy: 0.8434782608695652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       194\n",
      "           1       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.84       230\n",
      "   macro avg       0.42      0.50      0.46       230\n",
      "weighted avg       0.71      0.84      0.77       230\n",
      "\n",
      ">>14\n",
      "Accuracy: 0.8869565217391304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       204\n",
      "           1       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.89       230\n",
      "   macro avg       0.44      0.50      0.47       230\n",
      "weighted avg       0.79      0.89      0.83       230\n",
      "\n",
      ">>15\n",
      "Accuracy: 0.8434782608695652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.92       194\n",
      "           1       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.84       230\n",
      "   macro avg       0.42      0.50      0.46       230\n",
      "weighted avg       0.71      0.84      0.77       230\n",
      "\n",
      ">>16\n",
      "Accuracy: 0.8521739130434782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       196\n",
      "           1       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.85       230\n",
      "   macro avg       0.43      0.50      0.46       230\n",
      "weighted avg       0.73      0.85      0.78       230\n",
      "\n",
      ">>17\n",
      "Accuracy: 0.8347826086956521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91       192\n",
      "           1       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.83       230\n",
      "   macro avg       0.42      0.50      0.45       230\n",
      "weighted avg       0.70      0.83      0.76       230\n",
      "\n",
      ">>18\n",
      "Accuracy: 0.8478260869565217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92       195\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.85       230\n",
      "   macro avg       0.42      0.50      0.46       230\n",
      "weighted avg       0.72      0.85      0.78       230\n",
      "\n",
      ">>19\n",
      "Accuracy: 0.8391304347826087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91       193\n",
      "           1       0.00      0.00      0.00        37\n",
      "\n",
      "    accuracy                           0.84       230\n",
      "   macro avg       0.42      0.50      0.46       230\n",
      "weighted avg       0.70      0.84      0.77       230\n",
      "\n",
      "SVM + TFIDF\n",
      ">>0\n",
      "Accuracy: 0.8913043478260869\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94       196\n",
      "           1       0.71      0.44      0.55        34\n",
      "\n",
      "    accuracy                           0.89       230\n",
      "   macro avg       0.81      0.71      0.74       230\n",
      "weighted avg       0.88      0.89      0.88       230\n",
      "\n",
      ">>1\n",
      "Accuracy: 0.9173913043478261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       198\n",
      "           1       0.81      0.53      0.64        32\n",
      "\n",
      "    accuracy                           0.92       230\n",
      "   macro avg       0.87      0.76      0.80       230\n",
      "weighted avg       0.91      0.92      0.91       230\n",
      "\n",
      ">>2\n",
      "Accuracy: 0.8826086956521739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       193\n",
      "           1       0.73      0.43      0.54        37\n",
      "\n",
      "    accuracy                           0.88       230\n",
      "   macro avg       0.81      0.70      0.74       230\n",
      "weighted avg       0.87      0.88      0.87       230\n",
      "\n",
      ">>3\n",
      "Accuracy: 0.9043478260869565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       201\n",
      "           1       0.71      0.41      0.52        29\n",
      "\n",
      "    accuracy                           0.90       230\n",
      "   macro avg       0.81      0.69      0.73       230\n",
      "weighted avg       0.89      0.90      0.89       230\n",
      "\n",
      ">>4\n",
      "Accuracy: 0.8956521739130435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94       196\n",
      "           1       0.78      0.41      0.54        34\n",
      "\n",
      "    accuracy                           0.90       230\n",
      "   macro avg       0.84      0.70      0.74       230\n",
      "weighted avg       0.89      0.90      0.88       230\n",
      "\n",
      ">>5\n",
      "Accuracy: 0.8652173913043478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.97      0.92       185\n",
      "           1       0.79      0.42      0.55        45\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.83      0.70      0.74       230\n",
      "weighted avg       0.86      0.87      0.85       230\n",
      "\n",
      ">>6\n",
      "Accuracy: 0.8826086956521739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94       201\n",
      "           1       0.57      0.28      0.37        29\n",
      "\n",
      "    accuracy                           0.88       230\n",
      "   macro avg       0.74      0.62      0.65       230\n",
      "weighted avg       0.86      0.88      0.86       230\n",
      "\n",
      ">>7\n",
      "Accuracy: 0.9130434782608695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       199\n",
      "           1       0.74      0.55      0.63        31\n",
      "\n",
      "    accuracy                           0.91       230\n",
      "   macro avg       0.84      0.76      0.79       230\n",
      "weighted avg       0.91      0.91      0.91       230\n",
      "\n",
      ">>8\n",
      "Accuracy: 0.8826086956521739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       195\n",
      "           1       0.72      0.37      0.49        35\n",
      "\n",
      "    accuracy                           0.88       230\n",
      "   macro avg       0.81      0.67      0.71       230\n",
      "weighted avg       0.87      0.88      0.87       230\n",
      "\n",
      ">>9\n",
      "Accuracy: 0.8826086956521739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       193\n",
      "           1       0.75      0.41      0.53        37\n",
      "\n",
      "    accuracy                           0.88       230\n",
      "   macro avg       0.82      0.69      0.73       230\n",
      "weighted avg       0.87      0.88      0.87       230\n",
      "\n",
      ">>10\n",
      "Accuracy: 0.8652173913043478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       187\n",
      "           1       0.77      0.40      0.52        43\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.82      0.68      0.72       230\n",
      "weighted avg       0.86      0.87      0.85       230\n",
      "\n",
      ">>11\n",
      "Accuracy: 0.8826086956521739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.94       198\n",
      "           1       0.73      0.25      0.37        32\n",
      "\n",
      "    accuracy                           0.88       230\n",
      "   macro avg       0.81      0.62      0.65       230\n",
      "weighted avg       0.87      0.88      0.86       230\n",
      "\n",
      ">>12\n",
      "Accuracy: 0.9130434782608695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       199\n",
      "           1       0.74      0.55      0.63        31\n",
      "\n",
      "    accuracy                           0.91       230\n",
      "   macro avg       0.84      0.76      0.79       230\n",
      "weighted avg       0.91      0.91      0.91       230\n",
      "\n",
      ">>13\n",
      "Accuracy: 0.8652173913043478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92       191\n",
      "           1       0.70      0.36      0.47        39\n",
      "\n",
      "    accuracy                           0.87       230\n",
      "   macro avg       0.79      0.66      0.70       230\n",
      "weighted avg       0.85      0.87      0.85       230\n",
      "\n",
      ">>14\n",
      "Accuracy: 0.8826086956521739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.93       195\n",
      "           1       0.72      0.37      0.49        35\n",
      "\n",
      "    accuracy                           0.88       230\n",
      "   macro avg       0.81      0.67      0.71       230\n",
      "weighted avg       0.87      0.88      0.87       230\n",
      "\n",
      ">>15\n",
      "Accuracy: 0.908695652173913\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       193\n",
      "           1       0.83      0.54      0.66        37\n",
      "\n",
      "    accuracy                           0.91       230\n",
      "   macro avg       0.88      0.76      0.80       230\n",
      "weighted avg       0.90      0.91      0.90       230\n",
      "\n",
      ">>16\n",
      "Accuracy: 0.8956521739130435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       198\n",
      "           1       0.79      0.34      0.48        32\n",
      "\n",
      "    accuracy                           0.90       230\n",
      "   macro avg       0.84      0.66      0.71       230\n",
      "weighted avg       0.89      0.90      0.88       230\n",
      "\n",
      ">>17\n",
      "Accuracy: 0.8956521739130435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       194\n",
      "           1       0.83      0.42      0.56        36\n",
      "\n",
      "    accuracy                           0.90       230\n",
      "   macro avg       0.87      0.70      0.75       230\n",
      "weighted avg       0.89      0.90      0.88       230\n",
      "\n",
      ">>18\n",
      "Accuracy: 0.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94       196\n",
      "           1       0.82      0.41      0.55        34\n",
      "\n",
      "    accuracy                           0.90       230\n",
      "   macro avg       0.86      0.70      0.75       230\n",
      "weighted avg       0.89      0.90      0.89       230\n",
      "\n",
      ">>19\n",
      "Accuracy: 0.9130434782608695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       201\n",
      "           1       0.74      0.48      0.58        29\n",
      "\n",
      "    accuracy                           0.91       230\n",
      "   macro avg       0.83      0.73      0.77       230\n",
      "weighted avg       0.90      0.91      0.91       230\n",
      "\n",
      "LSTM + Word2Vec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-c4e92ed49592>:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"texto5\"] = df.apply(test,axis=1)\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\keras_preprocessing\\text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1781s 61s/step - loss: 0.5541 - accuracy: 0.8004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.19      0.33        36\n",
      "           1       0.87      1.00      0.93       191\n",
      "\n",
      "    accuracy                           0.87       227\n",
      "   macro avg       0.93      0.60      0.63       227\n",
      "weighted avg       0.89      0.87      0.83       227\n",
      "\n",
      ">>1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1656s 57s/step - loss: 0.5463 - accuracy: 0.8263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.18      0.31        38\n",
      "           1       0.86      1.00      0.92       189\n",
      "\n",
      "    accuracy                           0.86       227\n",
      "   macro avg       0.93      0.59      0.62       227\n",
      "weighted avg       0.88      0.86      0.82       227\n",
      "\n",
      ">>2\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1730s 60s/step - loss: 0.5280 - accuracy: 0.8370\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.31      0.47        36\n",
      "           1       0.88      1.00      0.94       191\n",
      "\n",
      "    accuracy                           0.89       227\n",
      "   macro avg       0.94      0.65      0.70       227\n",
      "weighted avg       0.90      0.89      0.86       227\n",
      "\n",
      ">>3\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1679s 58s/step - loss: 0.5109 - accuracy: 0.8217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.23      0.38        30\n",
      "           1       0.90      1.00      0.94       197\n",
      "\n",
      "    accuracy                           0.90       227\n",
      "   macro avg       0.95      0.62      0.66       227\n",
      "weighted avg       0.91      0.90      0.87       227\n",
      "\n",
      ">>4\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1620s 55s/step - loss: 0.5184 - accuracy: 0.8189\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.15      0.27        39\n",
      "           1       0.85      1.00      0.92       188\n",
      "\n",
      "    accuracy                           0.85       227\n",
      "   macro avg       0.93      0.58      0.59       227\n",
      "weighted avg       0.88      0.85      0.81       227\n",
      "\n",
      ">>5\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_5 (Spatial (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1784s 61s/step - loss: 0.6194 - accuracy: 0.7774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        35\n",
      "           1       0.85      1.00      0.92       192\n",
      "\n",
      "    accuracy                           0.85       227\n",
      "   macro avg       0.42      0.50      0.46       227\n",
      "weighted avg       0.72      0.85      0.78       227\n",
      "\n",
      ">>6\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_6 (Spatial (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1752s 60s/step - loss: 0.5023 - accuracy: 0.7955\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.21      0.35        33\n",
      "           1       0.88      1.00      0.94       194\n",
      "\n",
      "    accuracy                           0.89       227\n",
      "   macro avg       0.94      0.61      0.64       227\n",
      "weighted avg       0.90      0.89      0.85       227\n",
      "\n",
      ">>7\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_7 (Spatial (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1761s 61s/step - loss: 0.5706 - accuracy: 0.7773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.24      0.39        29\n",
      "           1       0.90      1.00      0.95       198\n",
      "\n",
      "    accuracy                           0.90       227\n",
      "   macro avg       0.95      0.62      0.67       227\n",
      "weighted avg       0.91      0.90      0.88       227\n",
      "\n",
      ">>8\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_8 (Spatial (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1684s 58s/step - loss: 0.5614 - accuracy: 0.7629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.24      0.37        34\n",
      "           1       0.88      0.99      0.93       193\n",
      "\n",
      "    accuracy                           0.88       227\n",
      "   macro avg       0.88      0.62      0.65       227\n",
      "weighted avg       0.88      0.88      0.85       227\n",
      "\n",
      ">>9\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_9 (Spatial (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1746s 60s/step - loss: 0.4877 - accuracy: 0.8231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.18      0.31        49\n",
      "           1       0.82      0.99      0.90       178\n",
      "\n",
      "    accuracy                           0.82       227\n",
      "   macro avg       0.86      0.59      0.60       227\n",
      "weighted avg       0.83      0.82      0.77       227\n",
      "\n",
      ">>10\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_10 (Spatia (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1758s 60s/step - loss: 0.5179 - accuracy: 0.7726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.27      0.41        26\n",
      "           1       0.91      1.00      0.95       201\n",
      "\n",
      "    accuracy                           0.91       227\n",
      "   macro avg       0.89      0.63      0.68       227\n",
      "weighted avg       0.91      0.91      0.89       227\n",
      "\n",
      ">>11\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_11 (Spatia (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1774s 61s/step - loss: 0.5253 - accuracy: 0.8292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.32      0.48        38\n",
      "           1       0.88      1.00      0.94       189\n",
      "\n",
      "    accuracy                           0.89       227\n",
      "   macro avg       0.94      0.66      0.71       227\n",
      "weighted avg       0.90      0.89      0.86       227\n",
      "\n",
      ">>12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_12 (Spatia (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1781s 61s/step - loss: 0.5365 - accuracy: 0.7904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.23      0.37        31\n",
      "           1       0.89      1.00      0.94       196\n",
      "\n",
      "    accuracy                           0.89       227\n",
      "   macro avg       0.95      0.61      0.66       227\n",
      "weighted avg       0.91      0.89      0.86       227\n",
      "\n",
      ">>13\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_13 (Spatia (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1793s 62s/step - loss: 0.5065 - accuracy: 0.7946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40        40\n",
      "           1       0.86      1.00      0.93       187\n",
      "\n",
      "    accuracy                           0.87       227\n",
      "   macro avg       0.93      0.62      0.66       227\n",
      "weighted avg       0.89      0.87      0.83       227\n",
      "\n",
      ">>14\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_14 (Spatia (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1754s 60s/step - loss: 0.5439 - accuracy: 0.7916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.18      0.31        38\n",
      "           1       0.86      1.00      0.92       189\n",
      "\n",
      "    accuracy                           0.86       227\n",
      "   macro avg       0.93      0.59      0.62       227\n",
      "weighted avg       0.88      0.86      0.82       227\n",
      "\n",
      ">>15\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_15 (Spatia (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1741s 60s/step - loss: 0.5047 - accuracy: 0.8366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.17      0.29        47\n",
      "           1       0.82      0.99      0.90       180\n",
      "\n",
      "    accuracy                           0.82       227\n",
      "   macro avg       0.85      0.58      0.59       227\n",
      "weighted avg       0.84      0.82      0.77       227\n",
      "\n",
      ">>16\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_16 (Spatia (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1766s 60s/step - loss: 0.5165 - accuracy: 0.8034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40        32\n",
      "           1       0.89      1.00      0.94       195\n",
      "\n",
      "    accuracy                           0.89       227\n",
      "   macro avg       0.95      0.62      0.67       227\n",
      "weighted avg       0.91      0.89      0.87       227\n",
      "\n",
      ">>17\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_17 (Spatia (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "29/29 [==============================] - 1752s 60s/step - loss: 0.5316 - accuracy: 0.8077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.15      0.27        26\n",
      "           1       0.90      1.00      0.95       201\n",
      "\n",
      "    accuracy                           0.90       227\n",
      "   macro avg       0.95      0.58      0.61       227\n",
      "weighted avg       0.91      0.90      0.87       227\n",
      "\n",
      ">>18\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_18 (Spatia (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1782s 60s/step - loss: 0.5207 - accuracy: 0.7890\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33        30\n",
      "           1       0.89      1.00      0.94       197\n",
      "\n",
      "    accuracy                           0.89       227\n",
      "   macro avg       0.95      0.60      0.64       227\n",
      "weighted avg       0.91      0.89      0.86       227\n",
      "\n",
      ">>19\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 3786, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_19 (Spatia (None, 3786, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      " 2/29 [=>............................] - ETA: 25:14 - loss: 0.6864 - accuracy: 0.6250"
     ]
    }
   ],
   "source": [
    "pipeline(df, df_bow, df_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meio a Meio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-bayes + BOW\n",
      ">>0\n",
      "Accuracy: 0.4857142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.54      0.54        39\n",
      "           1       0.42      0.42      0.42        31\n",
      "\n",
      "    accuracy                           0.49        70\n",
      "   macro avg       0.48      0.48      0.48        70\n",
      "weighted avg       0.49      0.49      0.49        70\n",
      "\n",
      ">>1\n",
      "Accuracy: 0.5142857142857142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.65      0.56        34\n",
      "           1       0.54      0.39      0.45        36\n",
      "\n",
      "    accuracy                           0.51        70\n",
      "   macro avg       0.52      0.52      0.51        70\n",
      "weighted avg       0.52      0.51      0.51        70\n",
      "\n",
      ">>2\n",
      "Accuracy: 0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.77      0.72        35\n",
      "           1       0.73      0.63      0.68        35\n",
      "\n",
      "    accuracy                           0.70        70\n",
      "   macro avg       0.70      0.70      0.70        70\n",
      "weighted avg       0.70      0.70      0.70        70\n",
      "\n",
      ">>3\n",
      "Accuracy: 0.7571428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.80        38\n",
      "           1       0.83      0.59      0.69        32\n",
      "\n",
      "    accuracy                           0.76        70\n",
      "   macro avg       0.77      0.74      0.75        70\n",
      "weighted avg       0.77      0.76      0.75        70\n",
      "\n",
      ">>4\n",
      "Accuracy: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.79      0.62        29\n",
      "           1       0.76      0.46      0.58        41\n",
      "\n",
      "    accuracy                           0.60        70\n",
      "   macro avg       0.64      0.63      0.60        70\n",
      "weighted avg       0.66      0.60      0.59        70\n",
      "\n",
      ">>5\n",
      "Accuracy: 0.6142857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.88      0.68        33\n",
      "           1       0.78      0.38      0.51        37\n",
      "\n",
      "    accuracy                           0.61        70\n",
      "   macro avg       0.67      0.63      0.60        70\n",
      "weighted avg       0.67      0.61      0.59        70\n",
      "\n",
      ">>6\n",
      "Accuracy: 0.6142857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.73      0.64        33\n",
      "           1       0.68      0.51      0.58        37\n",
      "\n",
      "    accuracy                           0.61        70\n",
      "   macro avg       0.62      0.62      0.61        70\n",
      "weighted avg       0.63      0.61      0.61        70\n",
      "\n",
      ">>7\n",
      "Accuracy: 0.6714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68        33\n",
      "           1       0.73      0.59      0.66        37\n",
      "\n",
      "    accuracy                           0.67        70\n",
      "   macro avg       0.68      0.68      0.67        70\n",
      "weighted avg       0.68      0.67      0.67        70\n",
      "\n",
      ">>8\n",
      "Accuracy: 0.6857142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70        31\n",
      "           1       0.81      0.56      0.67        39\n",
      "\n",
      "    accuracy                           0.69        70\n",
      "   macro avg       0.71      0.70      0.68        70\n",
      "weighted avg       0.72      0.69      0.68        70\n",
      "\n",
      ">>9\n",
      "Accuracy: 0.6571428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.84      0.69        32\n",
      "           1       0.79      0.50      0.61        38\n",
      "\n",
      "    accuracy                           0.66        70\n",
      "   macro avg       0.69      0.67      0.65        70\n",
      "weighted avg       0.70      0.66      0.65        70\n",
      "\n",
      ">>10\n",
      "Accuracy: 0.7142857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.91      0.75        33\n",
      "           1       0.87      0.54      0.67        37\n",
      "\n",
      "    accuracy                           0.71        70\n",
      "   macro avg       0.75      0.72      0.71        70\n",
      "weighted avg       0.76      0.71      0.71        70\n",
      "\n",
      ">>11\n",
      "Accuracy: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.67      0.61        33\n",
      "           1       0.65      0.54      0.59        37\n",
      "\n",
      "    accuracy                           0.60        70\n",
      "   macro avg       0.60      0.60      0.60        70\n",
      "weighted avg       0.61      0.60      0.60        70\n",
      "\n",
      ">>12\n",
      "Accuracy: 0.5285714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.68      0.58        34\n",
      "           1       0.56      0.39      0.46        36\n",
      "\n",
      "    accuracy                           0.53        70\n",
      "   macro avg       0.54      0.53      0.52        70\n",
      "weighted avg       0.54      0.53      0.52        70\n",
      "\n",
      ">>13\n",
      "Accuracy: 0.6285714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.79      0.70        39\n",
      "           1       0.62      0.42      0.50        31\n",
      "\n",
      "    accuracy                           0.63        70\n",
      "   macro avg       0.63      0.61      0.60        70\n",
      "weighted avg       0.63      0.63      0.61        70\n",
      "\n",
      ">>14\n",
      "Accuracy: 0.6857142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.71      0.65        28\n",
      "           1       0.78      0.67      0.72        42\n",
      "\n",
      "    accuracy                           0.69        70\n",
      "   macro avg       0.68      0.69      0.68        70\n",
      "weighted avg       0.70      0.69      0.69        70\n",
      "\n",
      ">>15\n",
      "Accuracy: 0.6571428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.85      0.70        33\n",
      "           1       0.78      0.49      0.60        37\n",
      "\n",
      "    accuracy                           0.66        70\n",
      "   macro avg       0.69      0.67      0.65        70\n",
      "weighted avg       0.69      0.66      0.65        70\n",
      "\n",
      ">>16\n",
      "Accuracy: 0.6714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.79      0.67        29\n",
      "           1       0.80      0.59      0.68        41\n",
      "\n",
      "    accuracy                           0.67        70\n",
      "   macro avg       0.69      0.69      0.67        70\n",
      "weighted avg       0.71      0.67      0.67        70\n",
      "\n",
      ">>17\n",
      "Accuracy: 0.6571428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.74      0.66        31\n",
      "           1       0.74      0.59      0.66        39\n",
      "\n",
      "    accuracy                           0.66        70\n",
      "   macro avg       0.67      0.67      0.66        70\n",
      "weighted avg       0.67      0.66      0.66        70\n",
      "\n",
      ">>18\n",
      "Accuracy: 0.6285714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.81      0.66        31\n",
      "           1       0.76      0.49      0.59        39\n",
      "\n",
      "    accuracy                           0.63        70\n",
      "   macro avg       0.66      0.65      0.63        70\n",
      "weighted avg       0.67      0.63      0.62        70\n",
      "\n",
      ">>19\n",
      "Accuracy: 0.6857142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.94      0.74        33\n",
      "           1       0.89      0.46      0.61        37\n",
      "\n",
      "    accuracy                           0.69        70\n",
      "   macro avg       0.75      0.70      0.67        70\n",
      "weighted avg       0.76      0.69      0.67        70\n",
      "\n",
      "SVM + BOW\n",
      ">>0\n",
      "Accuracy: 0.7285714285714285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.68      0.73        38\n",
      "           1       0.68      0.78      0.72        32\n",
      "\n",
      "    accuracy                           0.73        70\n",
      "   macro avg       0.73      0.73      0.73        70\n",
      "weighted avg       0.74      0.73      0.73        70\n",
      "\n",
      ">>1\n",
      "Accuracy: 0.6428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.63      0.66        38\n",
      "           1       0.60      0.66      0.63        32\n",
      "\n",
      "    accuracy                           0.64        70\n",
      "   macro avg       0.64      0.64      0.64        70\n",
      "weighted avg       0.65      0.64      0.64        70\n",
      "\n",
      ">>2\n",
      "Accuracy: 0.7428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        27\n",
      "           1       0.82      0.74      0.78        43\n",
      "\n",
      "    accuracy                           0.74        70\n",
      "   macro avg       0.73      0.74      0.74        70\n",
      "weighted avg       0.75      0.74      0.75        70\n",
      "\n",
      ">>3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.54      0.59        37\n",
      "           1       0.56      0.67      0.61        33\n",
      "\n",
      "    accuracy                           0.60        70\n",
      "   macro avg       0.60      0.60      0.60        70\n",
      "weighted avg       0.61      0.60      0.60        70\n",
      "\n",
      ">>4\n",
      "Accuracy: 0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.64      0.69        36\n",
      "           1       0.67      0.76      0.71        34\n",
      "\n",
      "    accuracy                           0.70        70\n",
      "   macro avg       0.70      0.70      0.70        70\n",
      "weighted avg       0.71      0.70      0.70        70\n",
      "\n",
      ">>5\n",
      "Accuracy: 0.7142857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.66      0.73        41\n",
      "           1       0.62      0.79      0.70        29\n",
      "\n",
      "    accuracy                           0.71        70\n",
      "   macro avg       0.72      0.73      0.71        70\n",
      "weighted avg       0.74      0.71      0.72        70\n",
      "\n",
      ">>6\n",
      "Accuracy: 0.6285714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.61        32\n",
      "           1       0.67      0.63      0.65        38\n",
      "\n",
      "    accuracy                           0.63        70\n",
      "   macro avg       0.63      0.63      0.63        70\n",
      "weighted avg       0.63      0.63      0.63        70\n",
      "\n",
      ">>7\n",
      "Accuracy: 0.7571428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80        42\n",
      "           1       0.70      0.68      0.69        28\n",
      "\n",
      "    accuracy                           0.76        70\n",
      "   macro avg       0.75      0.74      0.75        70\n",
      "weighted avg       0.76      0.76      0.76        70\n",
      "\n",
      ">>8\n",
      "Accuracy: 0.6857142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69        33\n",
      "           1       0.73      0.65      0.69        37\n",
      "\n",
      "    accuracy                           0.69        70\n",
      "   macro avg       0.69      0.69      0.69        70\n",
      "weighted avg       0.69      0.69      0.69        70\n",
      "\n",
      ">>9\n",
      "Accuracy: 0.7428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.68      0.72        34\n",
      "           1       0.72      0.81      0.76        36\n",
      "\n",
      "    accuracy                           0.74        70\n",
      "   macro avg       0.75      0.74      0.74        70\n",
      "weighted avg       0.75      0.74      0.74        70\n",
      "\n",
      ">>10\n",
      "Accuracy: 0.7142857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72        37\n",
      "           1       0.69      0.73      0.71        33\n",
      "\n",
      "    accuracy                           0.71        70\n",
      "   macro avg       0.71      0.71      0.71        70\n",
      "weighted avg       0.72      0.71      0.71        70\n",
      "\n",
      ">>11\n",
      "Accuracy: 0.6857142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70        38\n",
      "           1       0.65      0.69      0.67        32\n",
      "\n",
      "    accuracy                           0.69        70\n",
      "   macro avg       0.68      0.69      0.68        70\n",
      "weighted avg       0.69      0.69      0.69        70\n",
      "\n",
      ">>12\n",
      "Accuracy: 0.7428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        36\n",
      "           1       0.70      0.82      0.76        34\n",
      "\n",
      "    accuracy                           0.74        70\n",
      "   macro avg       0.75      0.75      0.74        70\n",
      "weighted avg       0.75      0.74      0.74        70\n",
      "\n",
      ">>13\n",
      "Accuracy: 0.6428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62        35\n",
      "           1       0.62      0.71      0.67        35\n",
      "\n",
      "    accuracy                           0.64        70\n",
      "   macro avg       0.65      0.64      0.64        70\n",
      "weighted avg       0.65      0.64      0.64        70\n",
      "\n",
      ">>14\n",
      "Accuracy: 0.7714285714285715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.72      0.78        39\n",
      "           1       0.70      0.84      0.76        31\n",
      "\n",
      "    accuracy                           0.77        70\n",
      "   macro avg       0.78      0.78      0.77        70\n",
      "weighted avg       0.78      0.77      0.77        70\n",
      "\n",
      ">>15\n",
      "Accuracy: 0.7428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.74        33\n",
      "           1       0.77      0.73      0.75        37\n",
      "\n",
      "    accuracy                           0.74        70\n",
      "   macro avg       0.74      0.74      0.74        70\n",
      "weighted avg       0.74      0.74      0.74        70\n",
      "\n",
      ">>16\n",
      "Accuracy: 0.6714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.78      0.68        32\n",
      "           1       0.76      0.58      0.66        38\n",
      "\n",
      "    accuracy                           0.67        70\n",
      "   macro avg       0.68      0.68      0.67        70\n",
      "weighted avg       0.69      0.67      0.67        70\n",
      "\n",
      ">>17\n",
      "Accuracy: 0.7571428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.73      0.76        37\n",
      "           1       0.72      0.79      0.75        33\n",
      "\n",
      "    accuracy                           0.76        70\n",
      "   macro avg       0.76      0.76      0.76        70\n",
      "weighted avg       0.76      0.76      0.76        70\n",
      "\n",
      ">>18\n",
      "Accuracy: 0.6714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67        35\n",
      "           1       0.67      0.69      0.68        35\n",
      "\n",
      "    accuracy                           0.67        70\n",
      "   macro avg       0.67      0.67      0.67        70\n",
      "weighted avg       0.67      0.67      0.67        70\n",
      "\n",
      ">>19\n",
      "Accuracy: 0.7285714285714285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.83      0.75        35\n",
      "           1       0.79      0.63      0.70        35\n",
      "\n",
      "    accuracy                           0.73        70\n",
      "   macro avg       0.74      0.73      0.73        70\n",
      "weighted avg       0.74      0.73      0.73        70\n",
      "\n",
      "Naive-bayes + TFIDF\n",
      ">>0\n",
      "Accuracy: 0.35714285714285715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        45\n",
      "           1       0.36      1.00      0.53        25\n",
      "\n",
      "    accuracy                           0.36        70\n",
      "   macro avg       0.18      0.50      0.26        70\n",
      "weighted avg       0.13      0.36      0.19        70\n",
      "\n",
      ">>1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4857142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      1.00      0.62        30\n",
      "           1       1.00      0.10      0.18        40\n",
      "\n",
      "    accuracy                           0.49        70\n",
      "   macro avg       0.73      0.55      0.40        70\n",
      "weighted avg       0.77      0.49      0.37        70\n",
      "\n",
      ">>2\n",
      "Accuracy: 0.5714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.32      0.44        38\n",
      "           1       0.52      0.88      0.65        32\n",
      "\n",
      "    accuracy                           0.57        70\n",
      "   macro avg       0.63      0.60      0.55        70\n",
      "weighted avg       0.64      0.57      0.54        70\n",
      "\n",
      ">>3\n",
      "Accuracy: 0.4714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.26      0.35        38\n",
      "           1       0.45      0.72      0.55        32\n",
      "\n",
      "    accuracy                           0.47        70\n",
      "   macro avg       0.49      0.49      0.45        70\n",
      "weighted avg       0.49      0.47      0.44        70\n",
      "\n",
      ">>4\n",
      "Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      1.00      0.63        30\n",
      "           1       1.00      0.12      0.22        40\n",
      "\n",
      "    accuracy                           0.50        70\n",
      "   macro avg       0.73      0.56      0.43        70\n",
      "weighted avg       0.77      0.50      0.40        70\n",
      "\n",
      ">>5\n",
      "Accuracy: 0.6428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.49      0.59        37\n",
      "           1       0.59      0.82      0.68        33\n",
      "\n",
      "    accuracy                           0.64        70\n",
      "   macro avg       0.67      0.65      0.64        70\n",
      "weighted avg       0.67      0.64      0.63        70\n",
      "\n",
      ">>6\n",
      "Accuracy: 0.7428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.63      0.71        35\n",
      "           1       0.70      0.86      0.77        35\n",
      "\n",
      "    accuracy                           0.74        70\n",
      "   macro avg       0.76      0.74      0.74        70\n",
      "weighted avg       0.76      0.74      0.74        70\n",
      "\n",
      ">>7\n",
      "Accuracy: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.32      0.46        37\n",
      "           1       0.55      0.91      0.68        33\n",
      "\n",
      "    accuracy                           0.60        70\n",
      "   macro avg       0.67      0.62      0.57        70\n",
      "weighted avg       0.68      0.60      0.57        70\n",
      "\n",
      ">>8\n",
      "Accuracy: 0.34285714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      1.00      0.51        24\n",
      "           1       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.34        70\n",
      "   macro avg       0.17      0.50      0.26        70\n",
      "weighted avg       0.12      0.34      0.18        70\n",
      "\n",
      ">>9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5285714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.18      0.30        38\n",
      "           1       0.49      0.94      0.65        32\n",
      "\n",
      "    accuracy                           0.53        70\n",
      "   macro avg       0.63      0.56      0.47        70\n",
      "weighted avg       0.65      0.53      0.46        70\n",
      "\n",
      ">>10\n",
      "Accuracy: 0.6857142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75        33\n",
      "           1       1.00      0.41      0.58        37\n",
      "\n",
      "    accuracy                           0.69        70\n",
      "   macro avg       0.80      0.70      0.66        70\n",
      "weighted avg       0.81      0.69      0.66        70\n",
      "\n",
      ">>11\n",
      "Accuracy: 0.6285714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.66      0.64        35\n",
      "           1       0.64      0.60      0.62        35\n",
      "\n",
      "    accuracy                           0.63        70\n",
      "   macro avg       0.63      0.63      0.63        70\n",
      "weighted avg       0.63      0.63      0.63        70\n",
      "\n",
      ">>12\n",
      "Accuracy: 0.6285714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.54      0.59        35\n",
      "           1       0.61      0.71      0.66        35\n",
      "\n",
      "    accuracy                           0.63        70\n",
      "   macro avg       0.63      0.63      0.63        70\n",
      "weighted avg       0.63      0.63      0.63        70\n",
      "\n",
      ">>13\n",
      "Accuracy: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        42\n",
      "           1       0.40      1.00      0.57        28\n",
      "\n",
      "    accuracy                           0.40        70\n",
      "   macro avg       0.20      0.50      0.29        70\n",
      "weighted avg       0.16      0.40      0.23        70\n",
      "\n",
      ">>14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.50      0.59        36\n",
      "           1       0.60      0.79      0.68        34\n",
      "\n",
      "    accuracy                           0.64        70\n",
      "   macro avg       0.66      0.65      0.64        70\n",
      "weighted avg       0.66      0.64      0.64        70\n",
      "\n",
      ">>15\n",
      "Accuracy: 0.6285714285714286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71        32\n",
      "           1       1.00      0.32      0.48        38\n",
      "\n",
      "    accuracy                           0.63        70\n",
      "   macro avg       0.78      0.66      0.60        70\n",
      "weighted avg       0.80      0.63      0.59        70\n",
      "\n",
      ">>16\n",
      "Accuracy: 0.5142857142857142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.26      0.37        39\n",
      "           1       0.47      0.84      0.60        31\n",
      "\n",
      "    accuracy                           0.51        70\n",
      "   macro avg       0.57      0.55      0.49        70\n",
      "weighted avg       0.58      0.51      0.47        70\n",
      "\n",
      ">>17\n",
      "Accuracy: 0.4714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      1.00      0.62        30\n",
      "           1       1.00      0.07      0.14        40\n",
      "\n",
      "    accuracy                           0.47        70\n",
      "   macro avg       0.72      0.54      0.38        70\n",
      "weighted avg       0.76      0.47      0.34        70\n",
      "\n",
      ">>18\n",
      "Accuracy: 0.6571428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73        33\n",
      "           1       1.00      0.35      0.52        37\n",
      "\n",
      "    accuracy                           0.66        70\n",
      "   macro avg       0.79      0.68      0.63        70\n",
      "weighted avg       0.80      0.66      0.62        70\n",
      "\n",
      ">>19\n",
      "Accuracy: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.97      0.63        31\n",
      "           1       0.83      0.13      0.22        39\n",
      "\n",
      "    accuracy                           0.50        70\n",
      "   macro avg       0.65      0.55      0.43        70\n",
      "weighted avg       0.67      0.50      0.40        70\n",
      "\n",
      "SVM + TFIDF\n",
      ">>0\n",
      "Accuracy: 0.7285714285714285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.89      0.77        35\n",
      "           1       0.83      0.57      0.68        35\n",
      "\n",
      "    accuracy                           0.73        70\n",
      "   macro avg       0.75      0.73      0.72        70\n",
      "weighted avg       0.75      0.73      0.72        70\n",
      "\n",
      ">>1\n",
      "Accuracy: 0.6428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.67        35\n",
      "           1       0.67      0.57      0.62        35\n",
      "\n",
      "    accuracy                           0.64        70\n",
      "   macro avg       0.65      0.64      0.64        70\n",
      "weighted avg       0.65      0.64      0.64        70\n",
      "\n",
      ">>2\n",
      "Accuracy: 0.7428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.83      0.74        30\n",
      "           1       0.84      0.68      0.75        40\n",
      "\n",
      "    accuracy                           0.74        70\n",
      "   macro avg       0.75      0.75      0.74        70\n",
      "weighted avg       0.76      0.74      0.74        70\n",
      "\n",
      ">>3\n",
      "Accuracy: 0.7428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74        31\n",
      "           1       0.82      0.69      0.75        39\n",
      "\n",
      "    accuracy                           0.74        70\n",
      "   macro avg       0.75      0.75      0.74        70\n",
      "weighted avg       0.76      0.74      0.74        70\n",
      "\n",
      ">>4\n",
      "Accuracy: 0.7571428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.70      0.73        33\n",
      "           1       0.75      0.81      0.78        37\n",
      "\n",
      "    accuracy                           0.76        70\n",
      "   macro avg       0.76      0.75      0.75        70\n",
      "weighted avg       0.76      0.76      0.76        70\n",
      "\n",
      ">>5\n",
      "Accuracy: 0.7142857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74        36\n",
      "           1       0.73      0.65      0.69        34\n",
      "\n",
      "    accuracy                           0.71        70\n",
      "   macro avg       0.72      0.71      0.71        70\n",
      "weighted avg       0.72      0.71      0.71        70\n",
      "\n",
      ">>6\n",
      "Accuracy: 0.7285714285714285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.79        41\n",
      "           1       0.73      0.55      0.63        29\n",
      "\n",
      "    accuracy                           0.73        70\n",
      "   macro avg       0.73      0.70      0.71        70\n",
      "weighted avg       0.73      0.73      0.72        70\n",
      "\n",
      ">>7\n",
      "Accuracy: 0.7571428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77        39\n",
      "           1       0.71      0.77      0.74        31\n",
      "\n",
      "    accuracy                           0.76        70\n",
      "   macro avg       0.76      0.76      0.76        70\n",
      "weighted avg       0.76      0.76      0.76        70\n",
      "\n",
      ">>8\n",
      "Accuracy: 0.7285714285714285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72        34\n",
      "           1       0.73      0.75      0.74        36\n",
      "\n",
      "    accuracy                           0.73        70\n",
      "   macro avg       0.73      0.73      0.73        70\n",
      "weighted avg       0.73      0.73      0.73        70\n",
      "\n",
      ">>9\n",
      "Accuracy: 0.7714285714285715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.84      0.77        32\n",
      "           1       0.84      0.71      0.77        38\n",
      "\n",
      "    accuracy                           0.77        70\n",
      "   macro avg       0.78      0.78      0.77        70\n",
      "weighted avg       0.78      0.77      0.77        70\n",
      "\n",
      ">>10\n",
      "Accuracy: 0.7428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.84      0.75        32\n",
      "           1       0.83      0.66      0.74        38\n",
      "\n",
      "    accuracy                           0.74        70\n",
      "   macro avg       0.75      0.75      0.74        70\n",
      "weighted avg       0.76      0.74      0.74        70\n",
      "\n",
      ">>11\n",
      "Accuracy: 0.7428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74        32\n",
      "           1       0.81      0.68      0.74        38\n",
      "\n",
      "    accuracy                           0.74        70\n",
      "   macro avg       0.75      0.75      0.74        70\n",
      "weighted avg       0.75      0.74      0.74        70\n",
      "\n",
      ">>12\n",
      "Accuracy: 0.7142857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.74      0.72        35\n",
      "           1       0.73      0.69      0.71        35\n",
      "\n",
      "    accuracy                           0.71        70\n",
      "   macro avg       0.71      0.71      0.71        70\n",
      "weighted avg       0.71      0.71      0.71        70\n",
      "\n",
      ">>13\n",
      "Accuracy: 0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74        40\n",
      "           1       0.66      0.63      0.64        30\n",
      "\n",
      "    accuracy                           0.70        70\n",
      "   macro avg       0.69      0.69      0.69        70\n",
      "weighted avg       0.70      0.70      0.70        70\n",
      "\n",
      ">>14\n",
      "Accuracy: 0.7857142857142857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81        37\n",
      "           1       0.82      0.70      0.75        33\n",
      "\n",
      "    accuracy                           0.79        70\n",
      "   macro avg       0.79      0.78      0.78        70\n",
      "weighted avg       0.79      0.79      0.78        70\n",
      "\n",
      ">>15\n",
      "Accuracy: 0.7571428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.95      0.80        37\n",
      "           1       0.90      0.55      0.68        33\n",
      "\n",
      "    accuracy                           0.76        70\n",
      "   macro avg       0.80      0.75      0.74        70\n",
      "weighted avg       0.79      0.76      0.75        70\n",
      "\n",
      ">>16\n",
      "Accuracy: 0.6428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69        40\n",
      "           1       0.59      0.57      0.58        30\n",
      "\n",
      "    accuracy                           0.64        70\n",
      "   macro avg       0.63      0.63      0.63        70\n",
      "weighted avg       0.64      0.64      0.64        70\n",
      "\n",
      ">>17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7571428571428571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.77        34\n",
      "           1       0.83      0.67      0.74        36\n",
      "\n",
      "    accuracy                           0.76        70\n",
      "   macro avg       0.77      0.76      0.76        70\n",
      "weighted avg       0.77      0.76      0.76        70\n",
      "\n",
      ">>18\n",
      "Accuracy: 0.7142857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.80      0.71        30\n",
      "           1       0.81      0.65      0.72        40\n",
      "\n",
      "    accuracy                           0.71        70\n",
      "   macro avg       0.72      0.73      0.71        70\n",
      "weighted avg       0.73      0.71      0.72        70\n",
      "\n",
      ">>19\n",
      "Accuracy: 0.7285714285714285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73        37\n",
      "           1       0.69      0.76      0.72        33\n",
      "\n",
      "    accuracy                           0.73        70\n",
      "   macro avg       0.73      0.73      0.73        70\n",
      "weighted avg       0.73      0.73      0.73        70\n",
      "\n",
      "LSTM + Word2Vec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\keras_preprocessing\\text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9/9 [==============================] - 475s 54s/step - loss: 0.6752 - accuracy: 0.6308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.34      0.47        38\n",
      "           1       0.53      0.88      0.66        32\n",
      "\n",
      "    accuracy                           0.59        70\n",
      "   macro avg       0.65      0.61      0.57        70\n",
      "weighted avg       0.66      0.59      0.56        70\n",
      "\n",
      ">>1\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9/9 [==============================] - 459s 51s/step - loss: 0.6772 - accuracy: 0.6191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.88      0.65        34\n",
      "           1       0.64      0.19      0.30        36\n",
      "\n",
      "    accuracy                           0.53        70\n",
      "   macro avg       0.57      0.54      0.47        70\n",
      "weighted avg       0.57      0.53      0.47        70\n",
      "\n",
      ">>2\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9/9 [==============================] - 518s 58s/step - loss: 0.6781 - accuracy: 0.5894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.61      0.67        33\n",
      "           1       0.70      0.81      0.75        37\n",
      "\n",
      "    accuracy                           0.71        70\n",
      "   macro avg       0.72      0.71      0.71        70\n",
      "weighted avg       0.72      0.71      0.71        70\n",
      "\n",
      ">>3\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9/9 [==============================] - 484s 54s/step - loss: 0.6821 - accuracy: 0.5329\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      1.00      0.61        26\n",
      "           1       1.00      0.25      0.40        44\n",
      "\n",
      "    accuracy                           0.53        70\n",
      "   macro avg       0.72      0.62      0.51        70\n",
      "weighted avg       0.79      0.53      0.48        70\n",
      "\n",
      ">>4\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_4 (Spatial (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9/9 [==============================] - 514s 57s/step - loss: 0.6948 - accuracy: 0.5768\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D2DA6AD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.53      0.68        45\n",
      "           1       0.52      0.92      0.67        25\n",
      "\n",
      "    accuracy                           0.67        70\n",
      "   macro avg       0.72      0.73      0.67        70\n",
      "weighted avg       0.78      0.67      0.67        70\n",
      "\n",
      ">>5\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_5 (Spatial (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9/9 [==============================] - 445s 49s/step - loss: 0.6816 - accuracy: 0.5548\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D181C7EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.31      0.39        32\n",
      "           1       0.57      0.76      0.65        38\n",
      "\n",
      "    accuracy                           0.56        70\n",
      "   macro avg       0.55      0.54      0.52        70\n",
      "weighted avg       0.55      0.56      0.53        70\n",
      "\n",
      ">>6\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_6 (Spatial (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9/9 [==============================] - 461s 52s/step - loss: 0.6808 - accuracy: 0.5912\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D16676B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.72        32\n",
      "           1       0.76      0.82      0.78        38\n",
      "\n",
      "    accuracy                           0.76        70\n",
      "   macro avg       0.76      0.75      0.75        70\n",
      "weighted avg       0.76      0.76      0.76        70\n",
      "\n",
      ">>7\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_7 (Spatial (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9/9 [==============================] - 487s 54s/step - loss: 0.6820 - accuracy: 0.5789\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D2DC65D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.86      0.78        36\n",
      "           1       0.81      0.62      0.70        34\n",
      "\n",
      "    accuracy                           0.74        70\n",
      "   macro avg       0.76      0.74      0.74        70\n",
      "weighted avg       0.75      0.74      0.74        70\n",
      "\n",
      ">>8\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_8 (Spatial (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9/9 [==============================] - 469s 52s/step - loss: 0.6746 - accuracy: 0.6126\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D19E07790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.86      0.74        37\n",
      "           1       0.76      0.48      0.59        33\n",
      "\n",
      "    accuracy                           0.69        70\n",
      "   macro avg       0.71      0.67      0.67        70\n",
      "weighted avg       0.70      0.69      0.67        70\n",
      "\n",
      ">>9\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_9 (Spatial (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 448s 50s/step - loss: 0.6802 - accuracy: 0.5867\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D2E060E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.56      0.68        34\n",
      "           1       0.69      0.92      0.79        36\n",
      "\n",
      "    accuracy                           0.74        70\n",
      "   macro avg       0.78      0.74      0.73        70\n",
      "weighted avg       0.77      0.74      0.73        70\n",
      "\n",
      ">>10\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_10 (Spatia (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9/9 [==============================] - 475s 54s/step - loss: 0.6793 - accuracy: 0.5977\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D1E84DE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.53      0.67        38\n",
      "           1       0.62      0.94      0.75        32\n",
      "\n",
      "    accuracy                           0.71        70\n",
      "   macro avg       0.77      0.73      0.71        70\n",
      "weighted avg       0.78      0.71      0.70        70\n",
      "\n",
      ">>11\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_11 (Spatia (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9/9 [==============================] - 526s 58s/step - loss: 0.7008 - accuracy: 0.6079\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D1817B310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.87      0.69        38\n",
      "           1       0.62      0.25      0.36        32\n",
      "\n",
      "    accuracy                           0.59        70\n",
      "   macro avg       0.60      0.56      0.53        70\n",
      "weighted avg       0.60      0.59      0.54        70\n",
      "\n",
      ">>12\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_12 (Spatia (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9/9 [==============================] - 524s 58s/step - loss: 0.6858 - accuracy: 0.4866\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D368E0700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.66      0.72        35\n",
      "           1       0.71      0.83      0.76        35\n",
      "\n",
      "    accuracy                           0.74        70\n",
      "   macro avg       0.75      0.74      0.74        70\n",
      "weighted avg       0.75      0.74      0.74        70\n",
      "\n",
      ">>13\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_13 (Spatia (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 545s 59s/step - loss: 0.6789 - accuracy: 0.5966\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D3764DCA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.89      0.67        35\n",
      "           1       0.67      0.23      0.34        35\n",
      "\n",
      "    accuracy                           0.56        70\n",
      "   macro avg       0.60      0.56      0.50        70\n",
      "weighted avg       0.60      0.56      0.50        70\n",
      "\n",
      ">>14\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_14 (Spatia (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9/9 [==============================] - 545s 60s/step - loss: 0.6827 - accuracy: 0.5634\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D3764D790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.78        33\n",
      "           1       0.81      0.78      0.79        37\n",
      "\n",
      "    accuracy                           0.79        70\n",
      "   macro avg       0.79      0.79      0.79        70\n",
      "weighted avg       0.79      0.79      0.79        70\n",
      "\n",
      ">>15\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_15 (Spatia (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9/9 [==============================] - 521s 58s/step - loss: 0.6773 - accuracy: 0.6261\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D19E07670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.50      0.63        40\n",
      "           1       0.57      0.90      0.70        30\n",
      "\n",
      "    accuracy                           0.67        70\n",
      "   macro avg       0.72      0.70      0.67        70\n",
      "weighted avg       0.74      0.67      0.66        70\n",
      "\n",
      ">>16\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_16 (Spatia (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9/9 [==============================] - 530s 59s/step - loss: 0.6810 - accuracy: 0.5796\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D192FC790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.51      0.64        35\n",
      "           1       0.65      0.91      0.76        35\n",
      "\n",
      "    accuracy                           0.71        70\n",
      "   macro avg       0.76      0.71      0.70        70\n",
      "weighted avg       0.76      0.71      0.70        70\n",
      "\n",
      ">>17\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_17 (Embedding)     (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_17 (Spatia (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 530s 59s/step - loss: 0.6785 - accuracy: 0.6108\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D16AEA040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.76      0.69        25\n",
      "           1       0.85      0.76      0.80        45\n",
      "\n",
      "    accuracy                           0.76        70\n",
      "   macro avg       0.74      0.76      0.75        70\n",
      "weighted avg       0.77      0.76      0.76        70\n",
      "\n",
      ">>18\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_18 (Spatia (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9/9 [==============================] - 506s 55s/step - loss: 0.6780 - accuracy: 0.6062\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D1E84D430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.93      0.81        29\n",
      "           1       0.94      0.73      0.82        41\n",
      "\n",
      "    accuracy                           0.81        70\n",
      "   macro avg       0.82      0.83      0.81        70\n",
      "weighted avg       0.84      0.81      0.82        70\n",
      "\n",
      ">>19\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 3395, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_19 (Spatia (None, 3395, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_19 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "9/9 [==============================] - 570s 64s/step - loss: 0.6855 - accuracy: 0.4758\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D17729790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.76        40\n",
      "           1       0.67      0.87      0.75        30\n",
      "\n",
      "    accuracy                           0.76        70\n",
      "   macro avg       0.77      0.77      0.76        70\n",
      "weighted avg       0.78      0.76      0.76        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_path = 'E:/Code/prf-recursos-multas/datasets/multas_v3.csv'\n",
    "df = pd.read_csv(df_path, encoding='utf-8',converters={\"texto3\": eval, \"texto4\": eval})\n",
    "\n",
    "dfi = df[ df['parecer'] == 'I' ][0:173]\n",
    "dfd = df[ df['parecer'] == 'D' ]\n",
    "\n",
    "df2 = pd.concat([dfi,dfd])\n",
    "df = df2.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "df_bow = gerar_bow_df(df)\n",
    "df_tfidf = gerar_tfidf_df(df_bow)\n",
    "\n",
    "pipeline(df, df_bow, df_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 para 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-bayes + BOW\n",
      ">>0\n",
      "Accuracy: 0.7980769230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.94      0.86        67\n",
      "           1       0.83      0.54      0.66        37\n",
      "\n",
      "    accuracy                           0.80       104\n",
      "   macro avg       0.81      0.74      0.76       104\n",
      "weighted avg       0.80      0.80      0.79       104\n",
      "\n",
      ">>1\n",
      "Accuracy: 0.7211538461538461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.81        66\n",
      "           1       0.71      0.39      0.51        38\n",
      "\n",
      "    accuracy                           0.72       104\n",
      "   macro avg       0.72      0.65      0.66       104\n",
      "weighted avg       0.72      0.72      0.70       104\n",
      "\n",
      ">>2\n",
      "Accuracy: 0.7115384615384616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.92      0.80        65\n",
      "           1       0.74      0.36      0.48        39\n",
      "\n",
      "    accuracy                           0.71       104\n",
      "   macro avg       0.72      0.64      0.64       104\n",
      "weighted avg       0.72      0.71      0.68       104\n",
      "\n",
      ">>3\n",
      "Accuracy: 0.7019230769230769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.93      0.79        61\n",
      "           1       0.80      0.37      0.51        43\n",
      "\n",
      "    accuracy                           0.70       104\n",
      "   macro avg       0.74      0.65      0.65       104\n",
      "weighted avg       0.73      0.70      0.67       104\n",
      "\n",
      ">>4\n",
      "Accuracy: 0.7980769230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.86        73\n",
      "           1       0.73      0.52      0.60        31\n",
      "\n",
      "    accuracy                           0.80       104\n",
      "   macro avg       0.77      0.72      0.73       104\n",
      "weighted avg       0.79      0.80      0.79       104\n",
      "\n",
      ">>5\n",
      "Accuracy: 0.7596153846153846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84        72\n",
      "           1       0.67      0.44      0.53        32\n",
      "\n",
      "    accuracy                           0.76       104\n",
      "   macro avg       0.72      0.67      0.68       104\n",
      "weighted avg       0.75      0.76      0.74       104\n",
      "\n",
      ">>6\n",
      "Accuracy: 0.7307692307692307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.90      0.81        68\n",
      "           1       0.68      0.42      0.52        36\n",
      "\n",
      "    accuracy                           0.73       104\n",
      "   macro avg       0.71      0.66      0.67       104\n",
      "weighted avg       0.72      0.73      0.71       104\n",
      "\n",
      ">>7\n",
      "Accuracy: 0.7019230769230769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.80        70\n",
      "           1       0.57      0.35      0.44        34\n",
      "\n",
      "    accuracy                           0.70       104\n",
      "   macro avg       0.65      0.61      0.62       104\n",
      "weighted avg       0.68      0.70      0.68       104\n",
      "\n",
      ">>8\n",
      "Accuracy: 0.7980769230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86        71\n",
      "           1       0.80      0.48      0.60        33\n",
      "\n",
      "    accuracy                           0.80       104\n",
      "   macro avg       0.80      0.71      0.73       104\n",
      "weighted avg       0.80      0.80      0.78       104\n",
      "\n",
      ">>9\n",
      "Accuracy: 0.7211538461538461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.95      0.81        65\n",
      "           1       0.81      0.33      0.47        39\n",
      "\n",
      "    accuracy                           0.72       104\n",
      "   macro avg       0.76      0.64      0.64       104\n",
      "weighted avg       0.75      0.72      0.68       104\n",
      "\n",
      ">>10\n",
      "Accuracy: 0.7403846153846154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.83        73\n",
      "           1       0.59      0.42      0.49        31\n",
      "\n",
      "    accuracy                           0.74       104\n",
      "   macro avg       0.69      0.65      0.66       104\n",
      "weighted avg       0.72      0.74      0.73       104\n",
      "\n",
      ">>11\n",
      "Accuracy: 0.7115384615384616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.92      0.80        66\n",
      "           1       0.72      0.34      0.46        38\n",
      "\n",
      "    accuracy                           0.71       104\n",
      "   macro avg       0.72      0.63      0.63       104\n",
      "weighted avg       0.71      0.71      0.68       104\n",
      "\n",
      ">>12\n",
      "Accuracy: 0.8365384615384616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89        72\n",
      "           1       0.86      0.56      0.68        32\n",
      "\n",
      "    accuracy                           0.84       104\n",
      "   macro avg       0.84      0.76      0.78       104\n",
      "weighted avg       0.84      0.84      0.83       104\n",
      "\n",
      ">>13\n",
      "Accuracy: 0.7307692307692307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.91      0.82        68\n",
      "           1       0.70      0.39      0.50        36\n",
      "\n",
      "    accuracy                           0.73       104\n",
      "   macro avg       0.72      0.65      0.66       104\n",
      "weighted avg       0.72      0.73      0.71       104\n",
      "\n",
      ">>14\n",
      "Accuracy: 0.8173076923076923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.99      0.88        68\n",
      "           1       0.95      0.50      0.65        36\n",
      "\n",
      "    accuracy                           0.82       104\n",
      "   macro avg       0.87      0.74      0.77       104\n",
      "weighted avg       0.84      0.82      0.80       104\n",
      "\n",
      ">>15\n",
      "Accuracy: 0.7403846153846154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.95      0.81        59\n",
      "           1       0.88      0.47      0.61        45\n",
      "\n",
      "    accuracy                           0.74       104\n",
      "   macro avg       0.79      0.71      0.71       104\n",
      "weighted avg       0.78      0.74      0.72       104\n",
      "\n",
      ">>16\n",
      "Accuracy: 0.7692307692307693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.83        64\n",
      "           1       0.77      0.57      0.66        40\n",
      "\n",
      "    accuracy                           0.77       104\n",
      "   macro avg       0.77      0.73      0.74       104\n",
      "weighted avg       0.77      0.77      0.76       104\n",
      "\n",
      ">>17\n",
      "Accuracy: 0.7884615384615384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.86        73\n",
      "           1       0.80      0.39      0.52        31\n",
      "\n",
      "    accuracy                           0.79       104\n",
      "   macro avg       0.79      0.67      0.69       104\n",
      "weighted avg       0.79      0.79      0.76       104\n",
      "\n",
      ">>18\n",
      "Accuracy: 0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83        69\n",
      "           1       0.70      0.46      0.55        35\n",
      "\n",
      "    accuracy                           0.75       104\n",
      "   macro avg       0.73      0.68      0.69       104\n",
      "weighted avg       0.74      0.75      0.73       104\n",
      "\n",
      ">>19\n",
      "Accuracy: 0.7403846153846154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.94      0.82        64\n",
      "           1       0.81      0.42      0.56        40\n",
      "\n",
      "    accuracy                           0.74       104\n",
      "   macro avg       0.77      0.68      0.69       104\n",
      "weighted avg       0.76      0.74      0.72       104\n",
      "\n",
      "SVM + BOW\n",
      ">>0\n",
      "Accuracy: 0.7115384615384616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.77        67\n",
      "           1       0.58      0.68      0.63        37\n",
      "\n",
      "    accuracy                           0.71       104\n",
      "   macro avg       0.69      0.70      0.70       104\n",
      "weighted avg       0.72      0.71      0.72       104\n",
      "\n",
      ">>1\n",
      "Accuracy: 0.7307692307692307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79        70\n",
      "           1       0.57      0.68      0.62        34\n",
      "\n",
      "    accuracy                           0.73       104\n",
      "   macro avg       0.70      0.72      0.71       104\n",
      "weighted avg       0.75      0.73      0.74       104\n",
      "\n",
      ">>2\n",
      "Accuracy: 0.7692307692307693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.83        73\n",
      "           1       0.61      0.65      0.62        31\n",
      "\n",
      "    accuracy                           0.77       104\n",
      "   macro avg       0.73      0.73      0.73       104\n",
      "weighted avg       0.77      0.77      0.77       104\n",
      "\n",
      ">>3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7596153846153846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82        69\n",
      "           1       0.65      0.63      0.64        35\n",
      "\n",
      "    accuracy                           0.76       104\n",
      "   macro avg       0.73      0.73      0.73       104\n",
      "weighted avg       0.76      0.76      0.76       104\n",
      "\n",
      ">>4\n",
      "Accuracy: 0.7307692307692307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80        71\n",
      "           1       0.58      0.58      0.58        33\n",
      "\n",
      "    accuracy                           0.73       104\n",
      "   macro avg       0.69      0.69      0.69       104\n",
      "weighted avg       0.73      0.73      0.73       104\n",
      "\n",
      ">>5\n",
      "Accuracy: 0.7019230769230769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.88      0.79        68\n",
      "           1       0.62      0.36      0.46        36\n",
      "\n",
      "    accuracy                           0.70       104\n",
      "   macro avg       0.67      0.62      0.63       104\n",
      "weighted avg       0.69      0.70      0.68       104\n",
      "\n",
      ">>6\n",
      "Accuracy: 0.7980769230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83        62\n",
      "           1       0.76      0.74      0.75        42\n",
      "\n",
      "    accuracy                           0.80       104\n",
      "   macro avg       0.79      0.79      0.79       104\n",
      "weighted avg       0.80      0.80      0.80       104\n",
      "\n",
      ">>7\n",
      "Accuracy: 0.7019230769230769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.78        74\n",
      "           1       0.49      0.57      0.52        30\n",
      "\n",
      "    accuracy                           0.70       104\n",
      "   macro avg       0.65      0.66      0.65       104\n",
      "weighted avg       0.72      0.70      0.71       104\n",
      "\n",
      ">>8\n",
      "Accuracy: 0.7692307692307693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.84        74\n",
      "           1       0.59      0.63      0.61        30\n",
      "\n",
      "    accuracy                           0.77       104\n",
      "   macro avg       0.72      0.73      0.72       104\n",
      "weighted avg       0.77      0.77      0.77       104\n",
      "\n",
      ">>9\n",
      "Accuracy: 0.7403846153846154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.81        76\n",
      "           1       0.51      0.64      0.57        28\n",
      "\n",
      "    accuracy                           0.74       104\n",
      "   macro avg       0.68      0.71      0.69       104\n",
      "weighted avg       0.76      0.74      0.75       104\n",
      "\n",
      ">>10\n",
      "Accuracy: 0.7115384615384616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.79        66\n",
      "           1       0.63      0.50      0.56        38\n",
      "\n",
      "    accuracy                           0.71       104\n",
      "   macro avg       0.69      0.67      0.67       104\n",
      "weighted avg       0.70      0.71      0.70       104\n",
      "\n",
      ">>11\n",
      "Accuracy: 0.7211538461538461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.79        69\n",
      "           1       0.59      0.57      0.58        35\n",
      "\n",
      "    accuracy                           0.72       104\n",
      "   macro avg       0.69      0.68      0.69       104\n",
      "weighted avg       0.72      0.72      0.72       104\n",
      "\n",
      ">>12\n",
      "Accuracy: 0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81        67\n",
      "           1       0.67      0.59      0.63        37\n",
      "\n",
      "    accuracy                           0.75       104\n",
      "   macro avg       0.73      0.72      0.72       104\n",
      "weighted avg       0.75      0.75      0.75       104\n",
      "\n",
      ">>13\n",
      "Accuracy: 0.7211538461538461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78        64\n",
      "           1       0.65      0.60      0.62        40\n",
      "\n",
      "    accuracy                           0.72       104\n",
      "   macro avg       0.70      0.70      0.70       104\n",
      "weighted avg       0.72      0.72      0.72       104\n",
      "\n",
      ">>14\n",
      "Accuracy: 0.7692307692307693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84        80\n",
      "           1       0.50      0.67      0.57        24\n",
      "\n",
      "    accuracy                           0.77       104\n",
      "   macro avg       0.69      0.73      0.71       104\n",
      "weighted avg       0.80      0.77      0.78       104\n",
      "\n",
      ">>15\n",
      "Accuracy: 0.7307692307692307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.75      0.80        73\n",
      "           1       0.54      0.68      0.60        31\n",
      "\n",
      "    accuracy                           0.73       104\n",
      "   macro avg       0.69      0.72      0.70       104\n",
      "weighted avg       0.75      0.73      0.74       104\n",
      "\n",
      ">>16\n",
      "Accuracy: 0.7403846153846154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80        67\n",
      "           1       0.63      0.65      0.64        37\n",
      "\n",
      "    accuracy                           0.74       104\n",
      "   macro avg       0.72      0.72      0.72       104\n",
      "weighted avg       0.74      0.74      0.74       104\n",
      "\n",
      ">>17\n",
      "Accuracy: 0.7115384615384616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76        62\n",
      "           1       0.64      0.64      0.64        42\n",
      "\n",
      "    accuracy                           0.71       104\n",
      "   macro avg       0.70      0.70      0.70       104\n",
      "weighted avg       0.71      0.71      0.71       104\n",
      "\n",
      ">>18\n",
      "Accuracy: 0.6634615384615384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.75        72\n",
      "           1       0.46      0.50      0.48        32\n",
      "\n",
      "    accuracy                           0.66       104\n",
      "   macro avg       0.61      0.62      0.61       104\n",
      "weighted avg       0.67      0.66      0.67       104\n",
      "\n",
      ">>19\n",
      "Accuracy: 0.7211538461538461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80        74\n",
      "           1       0.52      0.53      0.52        30\n",
      "\n",
      "    accuracy                           0.72       104\n",
      "   macro avg       0.66      0.67      0.66       104\n",
      "weighted avg       0.72      0.72      0.72       104\n",
      "\n",
      "Naive-bayes + TFIDF\n",
      ">>0\n",
      "Accuracy: 0.6826923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      1.00      0.81        71\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.68       104\n",
      "   macro avg       0.34      0.50      0.41       104\n",
      "weighted avg       0.47      0.68      0.55       104\n",
      "\n",
      ">>1\n",
      "Accuracy: 0.6538461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79        68\n",
      "           1       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.65       104\n",
      "   macro avg       0.33      0.50      0.40       104\n",
      "weighted avg       0.43      0.65      0.52       104\n",
      "\n",
      ">>2\n",
      "Accuracy: 0.6634615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80        69\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.66       104\n",
      "   macro avg       0.33      0.50      0.40       104\n",
      "weighted avg       0.44      0.66      0.53       104\n",
      "\n",
      ">>3\n",
      "Accuracy: 0.6346153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.78        66\n",
      "           1       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.63       104\n",
      "   macro avg       0.32      0.50      0.39       104\n",
      "weighted avg       0.40      0.63      0.49       104\n",
      "\n",
      ">>4\n",
      "Accuracy: 0.6346153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.78        66\n",
      "           1       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.63       104\n",
      "   macro avg       0.32      0.50      0.39       104\n",
      "weighted avg       0.40      0.63      0.49       104\n",
      "\n",
      ">>5\n",
      "Accuracy: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77        65\n",
      "           1       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.62       104\n",
      "   macro avg       0.31      0.50      0.38       104\n",
      "weighted avg       0.39      0.62      0.48       104\n",
      "\n",
      ">>6\n",
      "Accuracy: 0.6923076923076923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82        72\n",
      "           1       0.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.69       104\n",
      "   macro avg       0.35      0.50      0.41       104\n",
      "weighted avg       0.48      0.69      0.57       104\n",
      "\n",
      ">>7\n",
      "Accuracy: 0.6634615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80        69\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.66       104\n",
      "   macro avg       0.33      0.50      0.40       104\n",
      "weighted avg       0.44      0.66      0.53       104\n",
      "\n",
      ">>8\n",
      "Accuracy: 0.7019230769230769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82        73\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.70       104\n",
      "   macro avg       0.35      0.50      0.41       104\n",
      "weighted avg       0.49      0.70      0.58       104\n",
      "\n",
      ">>9\n",
      "Accuracy: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77        65\n",
      "           1       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.62       104\n",
      "   macro avg       0.31      0.50      0.38       104\n",
      "weighted avg       0.39      0.62      0.48       104\n",
      "\n",
      ">>10\n",
      "Accuracy: 0.6634615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80        69\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.66       104\n",
      "   macro avg       0.33      0.50      0.40       104\n",
      "weighted avg       0.44      0.66      0.53       104\n",
      "\n",
      ">>11\n",
      "Accuracy: 0.6346153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.78        66\n",
      "           1       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.63       104\n",
      "   macro avg       0.32      0.50      0.39       104\n",
      "weighted avg       0.40      0.63      0.49       104\n",
      "\n",
      ">>12\n",
      "Accuracy: 0.6730769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        70\n",
      "           1       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.67       104\n",
      "   macro avg       0.34      0.50      0.40       104\n",
      "weighted avg       0.45      0.67      0.54       104\n",
      "\n",
      ">>13\n",
      "Accuracy: 0.6442307692307693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78        67\n",
      "           1       0.00      0.00      0.00        37\n",
      "\n",
      "    accuracy                           0.64       104\n",
      "   macro avg       0.32      0.50      0.39       104\n",
      "weighted avg       0.42      0.64      0.50       104\n",
      "\n",
      ">>14\n",
      "Accuracy: 0.7211538461538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        75\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.72       104\n",
      "   macro avg       0.36      0.50      0.42       104\n",
      "weighted avg       0.52      0.72      0.60       104\n",
      "\n",
      ">>15\n",
      "Accuracy: 0.6346153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.78        66\n",
      "           1       0.00      0.00      0.00        38\n",
      "\n",
      "    accuracy                           0.63       104\n",
      "   macro avg       0.32      0.50      0.39       104\n",
      "weighted avg       0.40      0.63      0.49       104\n",
      "\n",
      ">>16\n",
      "Accuracy: 0.6057692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.75        63\n",
      "           1       0.00      0.00      0.00        41\n",
      "\n",
      "    accuracy                           0.61       104\n",
      "   macro avg       0.30      0.50      0.38       104\n",
      "weighted avg       0.37      0.61      0.46       104\n",
      "\n",
      ">>17\n",
      "Accuracy: 0.6538461538461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79        68\n",
      "           1       0.00      0.00      0.00        36\n",
      "\n",
      "    accuracy                           0.65       104\n",
      "   macro avg       0.33      0.50      0.40       104\n",
      "weighted avg       0.43      0.65      0.52       104\n",
      "\n",
      ">>18\n",
      "Accuracy: 0.6634615384615384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80        69\n",
      "           1       0.00      0.00      0.00        35\n",
      "\n",
      "    accuracy                           0.66       104\n",
      "   macro avg       0.33      0.50      0.40       104\n",
      "weighted avg       0.44      0.66      0.53       104\n",
      "\n",
      ">>19\n",
      "Accuracy: 0.6826923076923077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      1.00      0.81        71\n",
      "           1       0.00      0.00      0.00        33\n",
      "\n",
      "    accuracy                           0.68       104\n",
      "   macro avg       0.34      0.50      0.41       104\n",
      "weighted avg       0.47      0.68      0.55       104\n",
      "\n",
      "SVM + TFIDF\n",
      ">>0\n",
      "Accuracy: 0.7211538461538461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.95      0.80        60\n",
      "           1       0.86      0.41      0.55        44\n",
      "\n",
      "    accuracy                           0.72       104\n",
      "   macro avg       0.77      0.68      0.68       104\n",
      "weighted avg       0.76      0.72      0.69       104\n",
      "\n",
      ">>1\n",
      "Accuracy: 0.8557692307692307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.90        69\n",
      "           1       0.88      0.66      0.75        35\n",
      "\n",
      "    accuracy                           0.86       104\n",
      "   macro avg       0.87      0.81      0.83       104\n",
      "weighted avg       0.86      0.86      0.85       104\n",
      "\n",
      ">>2\n",
      "Accuracy: 0.7403846153846154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81        65\n",
      "           1       0.70      0.54      0.61        39\n",
      "\n",
      "    accuracy                           0.74       104\n",
      "   macro avg       0.73      0.70      0.71       104\n",
      "weighted avg       0.74      0.74      0.73       104\n",
      "\n",
      ">>3\n",
      "Accuracy: 0.7884615384615384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85        70\n",
      "           1       0.73      0.56      0.63        34\n",
      "\n",
      "    accuracy                           0.79       104\n",
      "   macro avg       0.77      0.73      0.74       104\n",
      "weighted avg       0.78      0.79      0.78       104\n",
      "\n",
      ">>4\n",
      "Accuracy: 0.7692307692307693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.83        67\n",
      "           1       0.74      0.54      0.62        37\n",
      "\n",
      "    accuracy                           0.77       104\n",
      "   macro avg       0.76      0.72      0.73       104\n",
      "weighted avg       0.77      0.77      0.76       104\n",
      "\n",
      ">>5\n",
      "Accuracy: 0.7980769230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85        67\n",
      "           1       0.77      0.62      0.69        37\n",
      "\n",
      "    accuracy                           0.80       104\n",
      "   macro avg       0.79      0.76      0.77       104\n",
      "weighted avg       0.80      0.80      0.79       104\n",
      "\n",
      ">>6\n",
      "Accuracy: 0.7980769230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86        66\n",
      "           1       0.87      0.53      0.66        38\n",
      "\n",
      "    accuracy                           0.80       104\n",
      "   macro avg       0.82      0.74      0.76       104\n",
      "weighted avg       0.81      0.80      0.78       104\n",
      "\n",
      ">>7\n",
      "Accuracy: 0.7788461538461539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85        71\n",
      "           1       0.73      0.48      0.58        33\n",
      "\n",
      "    accuracy                           0.78       104\n",
      "   macro avg       0.76      0.70      0.72       104\n",
      "weighted avg       0.77      0.78      0.76       104\n",
      "\n",
      ">>8\n",
      "Accuracy: 0.8173076923076923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87        68\n",
      "           1       0.84      0.58      0.69        36\n",
      "\n",
      "    accuracy                           0.82       104\n",
      "   macro avg       0.83      0.76      0.78       104\n",
      "weighted avg       0.82      0.82      0.81       104\n",
      "\n",
      ">>9\n",
      "Accuracy: 0.7692307692307693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84        67\n",
      "           1       0.78      0.49      0.60        37\n",
      "\n",
      "    accuracy                           0.77       104\n",
      "   macro avg       0.77      0.71      0.72       104\n",
      "weighted avg       0.77      0.77      0.75       104\n",
      "\n",
      ">>10\n",
      "Accuracy: 0.8653846153846154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91        74\n",
      "           1       0.90      0.60      0.72        30\n",
      "\n",
      "    accuracy                           0.87       104\n",
      "   macro avg       0.88      0.79      0.82       104\n",
      "weighted avg       0.87      0.87      0.86       104\n",
      "\n",
      ">>11\n",
      "Accuracy: 0.7788461538461539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85        70\n",
      "           1       0.72      0.53      0.61        34\n",
      "\n",
      "    accuracy                           0.78       104\n",
      "   macro avg       0.76      0.71      0.73       104\n",
      "weighted avg       0.77      0.78      0.77       104\n",
      "\n",
      ">>12\n",
      "Accuracy: 0.8173076923076923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.88        78\n",
      "           1       0.71      0.46      0.56        26\n",
      "\n",
      "    accuracy                           0.82       104\n",
      "   macro avg       0.77      0.70      0.72       104\n",
      "weighted avg       0.81      0.82      0.80       104\n",
      "\n",
      ">>13\n",
      "Accuracy: 0.7884615384615384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84        69\n",
      "           1       0.70      0.66      0.68        35\n",
      "\n",
      "    accuracy                           0.79       104\n",
      "   macro avg       0.76      0.76      0.76       104\n",
      "weighted avg       0.79      0.79      0.79       104\n",
      "\n",
      ">>14\n",
      "Accuracy: 0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.90      0.83        71\n",
      "           1       0.67      0.42      0.52        33\n",
      "\n",
      "    accuracy                           0.75       104\n",
      "   macro avg       0.72      0.66      0.67       104\n",
      "weighted avg       0.74      0.75      0.73       104\n",
      "\n",
      ">>15\n",
      "Accuracy: 0.7884615384615384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84        67\n",
      "           1       0.74      0.62      0.68        37\n",
      "\n",
      "    accuracy                           0.79       104\n",
      "   macro avg       0.78      0.75      0.76       104\n",
      "weighted avg       0.78      0.79      0.78       104\n",
      "\n",
      ">>16\n",
      "Accuracy: 0.7788461538461539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85        70\n",
      "           1       0.72      0.53      0.61        34\n",
      "\n",
      "    accuracy                           0.78       104\n",
      "   macro avg       0.76      0.71      0.73       104\n",
      "weighted avg       0.77      0.78      0.77       104\n",
      "\n",
      ">>17\n",
      "Accuracy: 0.8076923076923077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86        70\n",
      "           1       0.75      0.62      0.68        34\n",
      "\n",
      "    accuracy                           0.81       104\n",
      "   macro avg       0.79      0.76      0.77       104\n",
      "weighted avg       0.80      0.81      0.80       104\n",
      "\n",
      ">>18\n",
      "Accuracy: 0.7788461538461539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85        71\n",
      "           1       0.69      0.55      0.61        33\n",
      "\n",
      "    accuracy                           0.78       104\n",
      "   macro avg       0.75      0.72      0.73       104\n",
      "weighted avg       0.77      0.78      0.77       104\n",
      "\n",
      ">>19\n",
      "Accuracy: 0.7884615384615384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85        71\n",
      "           1       0.72      0.55      0.62        33\n",
      "\n",
      "    accuracy                           0.79       104\n",
      "   macro avg       0.77      0.72      0.74       104\n",
      "weighted avg       0.78      0.79      0.78       104\n",
      "\n",
      "LSTM + Word2Vec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Felipe\\anaconda3\\envs\\novo\\lib\\site-packages\\keras_preprocessing\\text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>0\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_20 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 808s 62s/step - loss: 0.6772 - accuracy: 0.6507\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013D15CBAE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.17      0.29        29\n",
      "           1       0.76      1.00      0.86        75\n",
      "\n",
      "    accuracy                           0.77       104\n",
      "   macro avg       0.88      0.59      0.58       104\n",
      "weighted avg       0.83      0.77      0.70       104\n",
      "\n",
      ">>1\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_21 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 822s 64s/step - loss: 0.6718 - accuracy: 0.6386\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.19      0.32        37\n",
      "           1       0.69      1.00      0.82        67\n",
      "\n",
      "    accuracy                           0.71       104\n",
      "   macro avg       0.85      0.59      0.57       104\n",
      "weighted avg       0.80      0.71      0.64       104\n",
      "\n",
      ">>2\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_22 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 901s 71s/step - loss: 0.7086 - accuracy: 0.6609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.46      0.62        28\n",
      "           1       0.83      0.99      0.90        76\n",
      "\n",
      "    accuracy                           0.85       104\n",
      "   macro avg       0.88      0.73      0.76       104\n",
      "weighted avg       0.86      0.85      0.83       104\n",
      "\n",
      ">>3\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_23 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_23 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 885s 68s/step - loss: 0.6544 - accuracy: 0.6276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25        28\n",
      "           1       0.76      1.00      0.86        76\n",
      "\n",
      "    accuracy                           0.77       104\n",
      "   macro avg       0.88      0.57      0.56       104\n",
      "weighted avg       0.82      0.77      0.70       104\n",
      "\n",
      ">>4\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_24 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 803s 62s/step - loss: 0.6792 - accuracy: 0.6224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33        40\n",
      "           1       0.67      1.00      0.80        64\n",
      "\n",
      "    accuracy                           0.69       104\n",
      "   macro avg       0.83      0.60      0.57       104\n",
      "weighted avg       0.79      0.69      0.62       104\n",
      "\n",
      ">>5\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_25 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_25 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 819s 64s/step - loss: 0.6661 - accuracy: 0.6496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.45      0.61        40\n",
      "           1       0.74      0.98      0.85        64\n",
      "\n",
      "    accuracy                           0.78       104\n",
      "   macro avg       0.84      0.72      0.73       104\n",
      "weighted avg       0.82      0.78      0.76       104\n",
      "\n",
      ">>6\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_26 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_26 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 838s 65s/step - loss: 0.6568 - accuracy: 0.6217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33        35\n",
      "           1       0.71      1.00      0.83        69\n",
      "\n",
      "    accuracy                           0.73       104\n",
      "   macro avg       0.86      0.60      0.58       104\n",
      "weighted avg       0.81      0.73      0.66       104\n",
      "\n",
      ">>7\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_27 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_27 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 790s 61s/step - loss: 0.6501 - accuracy: 0.6651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.21      0.35        38\n",
      "           1       0.69      1.00      0.81        66\n",
      "\n",
      "    accuracy                           0.71       104\n",
      "   macro avg       0.84      0.61      0.58       104\n",
      "weighted avg       0.80      0.71      0.64       104\n",
      "\n",
      ">>8\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_28 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_28 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_28 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 829s 65s/step - loss: 0.6596 - accuracy: 0.5498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.25      0.39        32\n",
      "           1       0.75      0.99      0.85        72\n",
      "\n",
      "    accuracy                           0.76       104\n",
      "   macro avg       0.82      0.62      0.62       104\n",
      "weighted avg       0.79      0.76      0.71       104\n",
      "\n",
      ">>9\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_29 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_29 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 857s 67s/step - loss: 0.6590 - accuracy: 0.6063\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        30\n",
      "           1       0.70      0.96      0.81        74\n",
      "\n",
      "    accuracy                           0.68       104\n",
      "   macro avg       0.35      0.48      0.41       104\n",
      "weighted avg       0.50      0.68      0.58       104\n",
      "\n",
      ">>10\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_30 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_30 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 812s 63s/step - loss: 0.7765 - accuracy: 0.6223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.41      0.58        32\n",
      "           1       0.79      1.00      0.88        72\n",
      "\n",
      "    accuracy                           0.82       104\n",
      "   macro avg       0.90      0.70      0.73       104\n",
      "weighted avg       0.86      0.82      0.79       104\n",
      "\n",
      ">>11\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_31 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_31 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 822s 64s/step - loss: 0.6417 - accuracy: 0.6289\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.09      0.16        35\n",
      "           1       0.68      1.00      0.81        69\n",
      "\n",
      "    accuracy                           0.69       104\n",
      "   macro avg       0.84      0.54      0.48       104\n",
      "weighted avg       0.79      0.69      0.59       104\n",
      "\n",
      ">>12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_32 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_32 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 810s 63s/step - loss: 0.6499 - accuracy: 0.6676\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.21      0.34        29\n",
      "           1       0.77      1.00      0.87        75\n",
      "\n",
      "    accuracy                           0.78       104\n",
      "   macro avg       0.88      0.60      0.60       104\n",
      "weighted avg       0.83      0.78      0.72       104\n",
      "\n",
      ">>13\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_33 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_33 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_33 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 790s 61s/step - loss: 0.6484 - accuracy: 0.7174\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33        35\n",
      "           1       0.71      1.00      0.83        69\n",
      "\n",
      "    accuracy                           0.73       104\n",
      "   macro avg       0.86      0.60      0.58       104\n",
      "weighted avg       0.81      0.73      0.66       104\n",
      "\n",
      ">>14\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_34 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_34 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_34 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 903s 71s/step - loss: 0.6491 - accuracy: 0.6960\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.22      0.36        36\n",
      "           1       0.71      1.00      0.83        68\n",
      "\n",
      "    accuracy                           0.73       104\n",
      "   macro avg       0.85      0.61      0.60       104\n",
      "weighted avg       0.81      0.73      0.67       104\n",
      "\n",
      ">>15\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_35 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_35 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_35 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 978s 77s/step - loss: 0.6629 - accuracy: 0.6171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.40      0.56        35\n",
      "           1       0.76      0.99      0.86        69\n",
      "\n",
      "    accuracy                           0.79       104\n",
      "   macro avg       0.85      0.69      0.71       104\n",
      "weighted avg       0.82      0.79      0.76       104\n",
      "\n",
      ">>16\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_36 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_36 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_36 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 917s 69s/step - loss: 0.6658 - accuracy: 0.5986\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.27      0.43        37\n",
      "           1       0.71      1.00      0.83        67\n",
      "\n",
      "    accuracy                           0.74       104\n",
      "   macro avg       0.86      0.64      0.63       104\n",
      "weighted avg       0.81      0.74      0.69       104\n",
      "\n",
      ">>17\n",
      "Model: \"sequential_37\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_37 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_37 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_37 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 795s 62s/step - loss: 0.6404 - accuracy: 0.6639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.32      0.48        34\n",
      "           1       0.75      0.99      0.85        70\n",
      "\n",
      "    accuracy                           0.77       104\n",
      "   macro avg       0.83      0.65      0.67       104\n",
      "weighted avg       0.80      0.77      0.73       104\n",
      "\n",
      ">>18\n",
      "Model: \"sequential_38\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_38 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_38 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_38 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 845s 65s/step - loss: 0.7404 - accuracy: 0.5631\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.22      0.36        37\n",
      "           1       0.70      1.00      0.82        67\n",
      "\n",
      "    accuracy                           0.72       104\n",
      "   macro avg       0.85      0.61      0.59       104\n",
      "weighted avg       0.81      0.72      0.66       104\n",
      "\n",
      ">>19\n",
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_39 (Embedding)     (None, 3433, 128)         25600     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_39 (Spatia (None, 3433, 128)         0         \n",
      "_________________________________________________________________\n",
      "lstm_39 (LSTM)               (None, 300)               514800    \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 2)                 602       \n",
      "=================================================================\n",
      "Total params: 541,002\n",
      "Trainable params: 541,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "13/13 [==============================] - 809s 63s/step - loss: 0.7052 - accuracy: 0.5838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40        40\n",
      "           1       0.68      1.00      0.81        64\n",
      "\n",
      "    accuracy                           0.71       104\n",
      "   macro avg       0.84      0.62      0.61       104\n",
      "weighted avg       0.80      0.71      0.65       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_path = 'E:/Code/prf-recursos-multas/datasets/multas_v3.csv'\n",
    "df = pd.read_csv(df_path, encoding='utf-8',converters={\"texto3\": eval, \"texto4\": eval})\n",
    "\n",
    "dfi = df[ df['parecer'] == 'I' ][0:173*2]\n",
    "dfd = df[ df['parecer'] == 'D' ]\n",
    "df2 = pd.concat([dfi,dfd])\n",
    "df = df2.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "df_bow = gerar_bow_df(df)\n",
    "df_tfidf = gerar_tfidf_df(df_bow)\n",
    "\n",
    "pipeline(df, df_bow, df_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
